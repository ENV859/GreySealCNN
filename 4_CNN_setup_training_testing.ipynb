{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN_training_testing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f0nIhYPcOgi"
      },
      "source": [
        "# Set up the CNN + model, Train it and Test it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwHi5FI7cOhG"
      },
      "source": [
        "**Before running this script, make sure that your Google Drive folder contains the tiles you created, the `tiling_scheme.json` file (`step 1`), and the 5 `csv` files that you created (`step 3`) to describe: the 3 data subsets (1 `csv` file), the annotations for each (3 `csv` files) and the class list (1 `csv` file).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gl7176/GreySealCNN/blob/master/4_CNN_setup_training_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "#####  <center> Be sure to update this hyperlink above if you clone and want to point to a different GitHub </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEW2teqYspQP"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XElcTShEQkh"
      },
      "source": [
        "### Connect to our Google Drive folder and pull all data\n",
        "Note: when you run this it will give you a link that you must click. You must give Google some permissions, then copy a code into a box that comes up in the output section of this code.\n",
        "\n",
        "If customizing this code, you will need to point the `drive_folder` variable to a URL for your shared google drive folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le3bfsAjzSP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f440d345-226e-41c5-e5a5-45604153fbe8"
      },
      "source": [
        "# set variable to the destination google drive folder you want to pull from\n",
        "drive_folder = 'https://drive.google.com/drive/folders/1INuRNVKvKMy8L_Nb6lmoVbyvScWK0-0D'\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# choose a local (colab) directory to store the data.\n",
        "local_download_path = os.path.expanduser('data')\n",
        "try:\n",
        "  os.makedirs(local_download_path)\n",
        "except: pass\n",
        "\n",
        "# 2. Auto-iterate using the query syntax\n",
        "#    https://developers.google.com/drive/v2/web/search-parameters\n",
        "\n",
        "# this bit points the code to that google drive folder\n",
        "pointer = str(\"'\" + drive_folder.split(\"/\")[-1] + \"'\" + \" in parents\")\n",
        "\n",
        "file_list = drive.ListFile(\n",
        "    {'q': pointer}).GetList()\n",
        "\n",
        "#    this bit pulls every file in the directory specified above\n",
        "image_list = []\n",
        "count = 0\n",
        "for f in file_list:\n",
        "  fname = os.path.join(local_download_path, f['title'])\n",
        "  if fname.endswith(\".png\"):\n",
        "    image_list.append(fname.split(\"/\")[1])\n",
        "    count += 1\n",
        "    if count % 10 == 0:\n",
        "      print(str(count) + \" tiles pulled\")\n",
        "  # 3. Create & download by id.\n",
        "  f_ = drive.CreateFile({'id': f['id']})\n",
        "  f_.GetContentFile(fname)\n",
        "  if fname.endswith(\".csv\") or fname.endswith(\".json\"):\n",
        "    print(\"Pulled file: \" + fname)\n",
        "print(str(count) + \" tiles pulled\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pulled file: data/tiling_scheme.json\n",
            "Pulled file: data/new_detections.json\n",
            "Pulled file: data/classes.csv\n",
            "Pulled file: data/annotations_train.csv\n",
            "Pulled file: data/annotations_test.csv\n",
            "Pulled file: data/subset_list.csv\n",
            "Pulled file: data/annotations_valid.csv\n",
            "Pulled file: data/via_SealCNN_TrainingData.csv\n",
            "10 tiles pulled\n",
            "20 tiles pulled\n",
            "30 tiles pulled\n",
            "40 tiles pulled\n",
            "50 tiles pulled\n",
            "60 tiles pulled\n",
            "70 tiles pulled\n",
            "80 tiles pulled\n",
            "90 tiles pulled\n",
            "100 tiles pulled\n",
            "110 tiles pulled\n",
            "120 tiles pulled\n",
            "130 tiles pulled\n",
            "140 tiles pulled\n",
            "150 tiles pulled\n",
            "160 tiles pulled\n",
            "170 tiles pulled\n",
            "180 tiles pulled\n",
            "190 tiles pulled\n",
            "200 tiles pulled\n",
            "210 tiles pulled\n",
            "220 tiles pulled\n",
            "230 tiles pulled\n",
            "240 tiles pulled\n",
            "244 tiles pulled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVqZgStvmrrI"
      },
      "source": [
        "### Identify necessary files from the input directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAvrvhCUmsZn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7f9b8eb-6b72-4d9d-f840-18f3cc35b7dc"
      },
      "source": [
        "import csv, json, glob\n",
        "\n",
        "# use this variable to set input directory\n",
        "input_dir = local_download_path\n",
        "\n",
        "training_data_file = 'annotations_train.csv'\n",
        "testing_data_file = 'annotations_test.csv'\n",
        "validation_data_file = 'annotations_valid.csv'\n",
        "classes_file = 'classes.csv'\n",
        "subset_list_file = 'subset_list.csv'\n",
        "tiling_scheme_file = 'tiling_scheme_placeholder'\n",
        "\n",
        "checklist = {training_data_file:\"training_data_file\", testing_data_file:\"testing_data_file\", \n",
        "             validation_data_file:\"validation_data_file\", classes_file:\"classes_file\",\n",
        "             subset_list_file:\"subset_list_file\", tiling_scheme_file:\"tiling_scheme_file\"}\n",
        "\n",
        "for fname in os.listdir(input_dir):\n",
        "  if fname.endswith(\".csv\"): \n",
        "    try: \n",
        "      vars()[checklist[fname]] = \"{i}/{f}\".format(i=input_dir, f=fname)\n",
        "      print(\"required file found: {v}\".format(v=vars()[checklist[fname]]))\n",
        "      del checklist[fname]\n",
        "    except: print(\"{f} detected but not listed among requirements\".format(f=fname))\n",
        "  if fname.endswith(\".json\"):\n",
        "    tiling_scheme_candidate = \"{i}/{f}\".format(i=input_dir, f=fname)\n",
        "    with open(tiling_scheme_candidate) as f:\n",
        "      try:\n",
        "        tile_list = json.load(f)[\"tile_pointers\"][\"image_locations\"]\n",
        "        tiling_scheme_file = tiling_scheme_candidate\n",
        "        print(\"required file found: {s}\".format(s=tiling_scheme_file))\n",
        "        del checklist['tiling_scheme_placeholder']\n",
        "      except: \n",
        "        print(\"{f} detected but not listed among requirements\".format(f=fname))\n",
        "\n",
        "if len(checklist) > 0:\n",
        "  for key in checklist:\n",
        "    print(\"Error: did not find {k} in your input folder\".format(k=key))\n",
        "  raise Exception(\"missing specified data files\")\n",
        "  \n",
        "# confirm that all files in tiling_scheme_file were pulled from Google Drive\n",
        "if len(tile_list) != len(image_list):\n",
        "  print('Step one produced {n1} tiles, but google drive contained {n2} images. Confirm that tile set is complete.\\n'.format(n1=len(tile_list), n2=len(image_list)))\n",
        "  raise Exception(\"tile count mismatch\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "required file found: data/classes.csv\n",
            "required file found: data/tiling_scheme.json\n",
            "required file found: data/subset_list.csv\n",
            "new_detections.json detected but not listed among requirements\n",
            "via_SealCNN_TrainingData.csv detected but not listed among requirements\n",
            "required file found: data/annotations_test.csv\n",
            "required file found: data/annotations_valid.csv\n",
            "required file found: data/annotations_train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-xdfna11L2F"
      },
      "source": [
        "### Install the Convolutional Neural Network that will do the detections. \n",
        "\n",
        "This section sets up the software and pulls code for a CNN model called \"RetinaNet\" which uses the model \"ResNet-50\" as a subcomponent. This section then loads data for an existing ResNet-50 model (pre-trained for object detection) which we will further train for our task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-VXXOfd-LXa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3ae93f91-5382-4822-e136-6b8d2ba293ee"
      },
      "source": [
        "# clear any existing builds and install the versions that work for us\n",
        "! pip uninstall --yes keras\n",
        "! pip install keras==2.4\n",
        "#! pip uninstall --yes tensorflow\n",
        "! pip install tensorflow==2.3.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling Keras-2.4.3:\n",
            "  Successfully uninstalled Keras-2.4.3\n",
            "Collecting keras==2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/19/9d8f1c86c09d05369da39b03d011cd689edef86c0e6b2777dbcedc49dfc6/Keras-2.4.0-py2.py3-none-any.whl (170kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.4) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.4) (1.4.1)\n",
            "Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.4) (2.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.4) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.4) (1.15.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (1.32.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (0.3.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (1.12)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (0.36.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (3.12.4)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (1.12.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (2.4.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (2.4.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (0.2.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (3.3.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (0.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow>=2.2.0->keras==2.4) (54.2.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (1.28.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (0.4.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (3.8.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (3.0.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (3.1.0)\n",
            "Installing collected packages: keras\n",
            "Successfully installed keras-2.4.0\n",
            "Collecting tensorflow==2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/89/f2d29c2eafc2eeafb17d5634340e06366af904d332341200a49d954bce85/tensorflow-2.3.0-cp37-cp37m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 51kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.12.1)\n",
            "Collecting numpy<1.19.0,>=1.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/c6/58e517e8b1fb192725cfa23c01c2e60e4e6699314ee9684a1c5f5c9b27e1/numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.1.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.3.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (2.4.1)\n",
            "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/ed/5853ec0ae380cba4588eab1524e18ece1583b65f7ae0e97321f5ff9dfd60/tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 37.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (3.12.4)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.32.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.36.2)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (2.10.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (54.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.28.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.10)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.7.4.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.1.0)\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed numpy-1.18.5 tensorflow-2.3.0 tensorflow-estimator-2.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jb7YRXlEUUg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6339326c-203f-4379-b0f8-8919451a29b2"
      },
      "source": [
        "# copy the files for RetinaNet\n",
        "# note that this build is now deprecated, but we are fine with that\n",
        "# now pulling from a personal clone that outputs error metrics\n",
        "! git clone https://github.com/gl7176/keras-retinanet.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-retinanet'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 6236 (delta 0), reused 0 (delta 0), pack-reused 6230\u001b[K\n",
            "Receiving objects: 100% (6236/6236), 13.48 MiB | 19.39 MiB/s, done.\n",
            "Resolving deltas: 100% (4218/4218), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuULO44w6yx8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3f8de50-383b-4862-a28a-1cc40de8d8a5"
      },
      "source": [
        "# change directory and install RetinaNet from the copied code\n",
        "% cd keras-retinanet\n",
        "\n",
        "! pip install ."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras-retinanet\n",
            "Processing /content/keras-retinanet\n",
            "Collecting keras-resnet==0.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/76/d4/a35cbd07381139dda4db42c81b88c59254faac026109022727b45b31bcad/keras-resnet-0.2.0.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==1.0.0) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==1.0.0) (1.18.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==1.0.0) (0.29.22)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==1.0.0) (7.1.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==1.0.0) (4.1.2.30)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==1.0.0) (3.38.0)\n",
            "Requirement already satisfied: keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from keras-resnet==0.2.0->keras-retinanet==1.0.0) (2.4.0)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from progressbar2->keras-retinanet==1.0.0) (2.5.6)\n",
            "Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (2.3.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (2.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (0.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.12.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (0.36.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.32.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (2.4.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (0.3.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (54.2.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.28.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (0.4.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (4.2.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (3.1.0)\n",
            "Building wheels for collected packages: keras-retinanet, keras-resnet\n",
            "  Building wheel for keras-retinanet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-retinanet: filename=keras_retinanet-1.0.0-cp37-cp37m-linux_x86_64.whl size=169793 sha256=95e32fae51a60c526cea76964d467040ec179419b0c3317b99634ccc07b65c58\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/9f/57/cb0305f6f5a41fc3c11ad67b8cedfbe9127775b563337827ba\n",
            "  Building wheel for keras-resnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-resnet: filename=keras_resnet-0.2.0-py2.py3-none-any.whl size=20486 sha256=d2d801c2cf00d9372ac4abdca1d09fc9cff1870ffa1bdc5e1929b6ad162b3354\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/09/a5/497a30fd9ad9964e98a1254d1e164bcd1b8a5eda36197ecb3c\n",
            "Successfully built keras-retinanet keras-resnet\n",
            "Installing collected packages: keras-resnet, keras-retinanet\n",
            "Successfully installed keras-resnet-0.2.0 keras-retinanet-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu_IOPbC44SC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b193a5ee-cd4d-4c7d-d029-e0549408b7d8"
      },
      "source": [
        "! python setup.py build_ext --inplace"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running build_ext\n",
            "cythoning keras_retinanet/utils/compute_overlap.pyx to keras_retinanet/utils/compute_overlap.c\n",
            "/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/keras-retinanet/keras_retinanet/utils/compute_overlap.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "building 'keras_retinanet.utils.compute_overlap' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/keras_retinanet\n",
            "creating build/temp.linux-x86_64-3.7/keras_retinanet/utils\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.7m -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -c keras_retinanet/utils/compute_overlap.c -o build/temp.linux-x86_64-3.7/keras_retinanet/utils/compute_overlap.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1832:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kkeras_retinanet/utils/compute_overlap.c:610\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/keras_retinanet\n",
            "creating build/lib.linux-x86_64-3.7/keras_retinanet/utils\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/keras_retinanet/utils/compute_overlap.o -o build/lib.linux-x86_64-3.7/keras_retinanet/utils/compute_overlap.cpython-37m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.7/keras_retinanet/utils/compute_overlap.cpython-37m-x86_64-linux-gnu.so -> keras_retinanet/utils\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33S3M0SoI1JI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a69031dc-ab94-4145-96ee-54ec25aeff2b"
      },
      "source": [
        "% cd ../\n",
        "\n",
        "# get the pre-trained ResNet-50 model\n",
        "! wget -P data \"https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "--2021-04-08 17:45:47--  https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5\n",
            "Resolving github.com (github.com)... 52.69.186.44\n",
            "Connecting to github.com (github.com)|52.69.186.44|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/100249425/b7184a80-9350-11e9-9cc2-454f5c616394?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210408%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210408T174547Z&X-Amz-Expires=300&X-Amz-Signature=b86a2887d227df64db0bbf82db5a52364c27f63766c6a95b44716faa31fed1a9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=100249425&response-content-disposition=attachment%3B%20filename%3Dresnet50_coco_best_v2.1.0.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-04-08 17:45:47--  https://github-releases.githubusercontent.com/100249425/b7184a80-9350-11e9-9cc2-454f5c616394?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210408%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210408T174547Z&X-Amz-Expires=300&X-Amz-Signature=b86a2887d227df64db0bbf82db5a52364c27f63766c6a95b44716faa31fed1a9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=100249425&response-content-disposition=attachment%3B%20filename%3Dresnet50_coco_best_v2.1.0.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 152662144 (146M) [application/octet-stream]\n",
            "Saving to: ‘data/resnet50_coco_best_v2.1.0.h5’\n",
            "\n",
            "resnet50_coco_best_ 100%[===================>] 145.59M  21.6MB/s    in 6.9s    \n",
            "\n",
            "2021-04-08 17:45:55 (21.1 MB/s) - ‘data/resnet50_coco_best_v2.1.0.h5’ saved [152662144/152662144]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYBUnE6wEKuq"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzdoAR2GEKuv"
      },
      "source": [
        "We're giving our model the pre-trained weights that we downloaded above, and then we're telling it to use the `training_data_file`, to run with hyper-parameters `epoch_number` and `batch_size_number`.\n",
        "\n",
        "An epoch is a group of steps after which the model calculates its accuracy; the epoch parameter is the maximum number the training will run before stopping; in this framework the model will stop running once it stops improving (based on mAP) for multiple epochs, determined by a 'patience' variable (here, 5).\n",
        "\n",
        "A step is an increment of training the model on one batch or subset of files. The step size is limited on the upper bound by the training data (divided into batches), which we calculate in the code.\n",
        "\n",
        "A batch is the number of images being analyzed in each step. Batch-size is functionally limited by RAM (how many images the computer can store in memory), and given our default tile size, Colab runs out of memory at batch sizes larger than 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94Xz9e-HWdIa",
        "outputId": "724eda28-d8ca-4332-fb8f-1d15a574e42f"
      },
      "source": [
        "# Pull the total number of training images so we can calculate the maximum step number\n",
        "\n",
        "import csv\n",
        "\n",
        "training_subset_count = 0\n",
        "with open(subset_list_file) as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    for row in reader:\n",
        "      if \"training\" in row:\n",
        "        training_subset_count += 1\n",
        "print(training_subset_count)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q_jz-8wdJ-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d87f7db6-101b-441b-f3e3-ec2cd0674db2"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "epoch_number = 50\n",
        "batch_size_number = 2\n",
        "step_number = int(training_subset_count/batch_size_number)\n",
        "print(str(step_number) + \" steps\")\n",
        "\n",
        "# the following code that gets passed to the terminal, but we've moved it into a\n",
        "# subprocess that pulls variables instead; use terminal code for troubleshooting\n",
        "\n",
        "#! keras-retinanet/keras_retinanet/bin/train.py \\\n",
        "#--weights data/resnet50_coco_best_v2.1.0.h5 \\\n",
        "#--epochs 50 --steps 52 --batch-size 4 \\\n",
        "#csv data/annotations_train.csv data/classes.csv \\\n",
        "#--val-annotations data/annotations_valid.csv\n",
        "\n",
        "# this process takes a while to run, be warned! Consider running in terminal commands\n",
        "# (commented out above) if you want to see the live output as it's running\n",
        "\n",
        "# you can also monitor epoch outputs by output files in the \"output\" folder\n",
        "\n",
        "model_run = subprocess.check_output(['keras-retinanet/keras_retinanet/bin/train.py',\n",
        "                 '--weights', 'data/resnet50_coco_best_v2.1.0.h5',\n",
        "                 '--epochs', str(epoch_number),  '--steps', str(step_number), '--batch-size',\n",
        "                 str(batch_size_number), 'csv', training_data_file, classes_file,\n",
        "                 '--val-annotations', validation_data_file]).decode(\"utf-8\")\n",
        "print(model_run)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "105 steps\n",
            "2021-04-08 17:48:13.545474: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Using TensorFlow backend.\n",
            "Creating model, this may take a second...\n",
            "2021-04-08 17:48:15.190431: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2021-04-08 17:48:15.221784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 17:48:15.222563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2021-04-08 17:48:15.222615: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-04-08 17:48:15.225083: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2021-04-08 17:48:15.227131: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2021-04-08 17:48:15.227541: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2021-04-08 17:48:15.229762: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-04-08 17:48:15.231072: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-04-08 17:48:15.235362: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-04-08 17:48:15.235504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 17:48:15.236365: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 17:48:15.237194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2021-04-08 17:48:15.237561: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-04-08 17:48:15.243966: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2299995000 Hz\n",
            "2021-04-08 17:48:15.244252: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562576be4d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-04-08 17:48:15.244290: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-04-08 17:48:15.301782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 17:48:15.302684: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562576be4f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-04-08 17:48:15.302719: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2021-04-08 17:48:15.302953: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 17:48:15.303725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2021-04-08 17:48:15.303813: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-04-08 17:48:15.303872: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2021-04-08 17:48:15.303923: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2021-04-08 17:48:15.303963: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2021-04-08 17:48:15.304000: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-04-08 17:48:15.304043: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-04-08 17:48:15.304085: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-04-08 17:48:15.304197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 17:48:15.305039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 17:48:15.305787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2021-04-08 17:48:15.305859: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-04-08 17:48:15.760297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-04-08 17:48:15.760375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2021-04-08 17:48:15.760394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2021-04-08 17:48:15.760637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 17:48:15.761577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 17:48:15.762394: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-04-08 17:48:15.762457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10626 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:Skipping loading of weights for layer classification_submodel due to mismatch in shape ((3, 3, 256, 18) vs (3, 3, 256, 720)).\n",
            "WARNING:tensorflow:Skipping loading of weights for layer classification_submodel due to mismatch in shape ((18,) vs (720,)).\n",
            "Model: \"retinanet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, None, None, 6 9408        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, None, None, 6 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, None, None, 6 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, None, None, 6 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, None, None, 6 4096        pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, None, None, 6 256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a_relu (Activation (None, None, None, 6 0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding2a_branch2b (ZeroPadding (None, None, None, 6 0           res2a_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, None, None, 6 36864       padding2a_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, None, None, 6 256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b_relu (Activation (None, None, None, 6 0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, None, None, 2 16384       res2a_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, None, None, 2 16384       pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a (Add)                     (None, None, None, 2 0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_relu (Activation)         (None, None, None, 2 0           res2a[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, None, None, 6 16384       res2a_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, None, None, 6 256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a_relu (Activation (None, None, None, 6 0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding2b_branch2b (ZeroPadding (None, None, None, 6 0           res2b_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, None, None, 6 36864       padding2b_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, None, None, 6 256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b_relu (Activation (None, None, None, 6 0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, None, None, 2 16384       res2b_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2b (Add)                     (None, None, None, 2 0           bn2b_branch2c[0][0]              \n",
            "                                                                 res2a_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2b_relu (Activation)         (None, None, None, 2 0           res2b[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, None, None, 6 16384       res2b_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, None, None, 6 256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a_relu (Activation (None, None, None, 6 0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding2c_branch2b (ZeroPadding (None, None, None, 6 0           res2c_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, None, None, 6 36864       padding2c_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, None, None, 6 256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b_relu (Activation (None, None, None, 6 0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, None, None, 2 16384       res2c_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2c (Add)                     (None, None, None, 2 0           bn2c_branch2c[0][0]              \n",
            "                                                                 res2b_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2c_relu (Activation)         (None, None, None, 2 0           res2c[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, None, None, 1 32768       res2c_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, None, None, 1 512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a_relu (Activation (None, None, None, 1 0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding3a_branch2b (ZeroPadding (None, None, None, 1 0           res3a_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, None, None, 1 147456      padding3a_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, None, None, 1 512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b_relu (Activation (None, None, None, 1 0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, None, None, 5 65536       res3a_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, None, None, 5 131072      res2c_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a (Add)                     (None, None, None, 5 0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_relu (Activation)         (None, None, None, 5 0           res3a[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, None, None, 1 65536       res3a_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, None, None, 1 512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a_relu (Activation (None, None, None, 1 0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding3b_branch2b (ZeroPadding (None, None, None, 1 0           res3b_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, None, None, 1 147456      padding3b_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, None, None, 1 512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b_relu (Activation (None, None, None, 1 0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, None, None, 5 65536       res3b_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3b (Add)                     (None, None, None, 5 0           bn3b_branch2c[0][0]              \n",
            "                                                                 res3a_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res3b_relu (Activation)         (None, None, None, 5 0           res3b[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, None, None, 1 65536       res3b_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, None, None, 1 512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a_relu (Activation (None, None, None, 1 0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding3c_branch2b (ZeroPadding (None, None, None, 1 0           res3c_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, None, None, 1 147456      padding3c_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, None, None, 1 512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b_relu (Activation (None, None, None, 1 0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, None, None, 5 65536       res3c_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3c (Add)                     (None, None, None, 5 0           bn3c_branch2c[0][0]              \n",
            "                                                                 res3b_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res3c_relu (Activation)         (None, None, None, 5 0           res3c[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, None, None, 1 65536       res3c_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, None, None, 1 512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a_relu (Activation (None, None, None, 1 0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding3d_branch2b (ZeroPadding (None, None, None, 1 0           res3d_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, None, None, 1 147456      padding3d_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, None, None, 1 512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b_relu (Activation (None, None, None, 1 0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, None, None, 5 65536       res3d_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3d (Add)                     (None, None, None, 5 0           bn3d_branch2c[0][0]              \n",
            "                                                                 res3c_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res3d_relu (Activation)         (None, None, None, 5 0           res3d[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, None, None, 2 131072      res3d_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a_relu (Activation (None, None, None, 2 0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding4a_branch2b (ZeroPadding (None, None, None, 2 0           res4a_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, None, None, 2 589824      padding4a_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b_relu (Activation (None, None, None, 2 0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, None, None, 1 262144      res4a_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, None, None, 1 524288      res3d_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a (Add)                     (None, None, None, 1 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res4a_relu (Activation)         (None, None, None, 1 0           res4a[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, None, None, 2 262144      res4a_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a_relu (Activation (None, None, None, 2 0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding4b_branch2b (ZeroPadding (None, None, None, 2 0           res4b_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, None, None, 2 589824      padding4b_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b_relu (Activation (None, None, None, 2 0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, None, None, 1 262144      res4b_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4b (Add)                     (None, None, None, 1 0           bn4b_branch2c[0][0]              \n",
            "                                                                 res4a_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4b_relu (Activation)         (None, None, None, 1 0           res4b[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, None, None, 2 262144      res4b_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a_relu (Activation (None, None, None, 2 0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding4c_branch2b (ZeroPadding (None, None, None, 2 0           res4c_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, None, None, 2 589824      padding4c_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b_relu (Activation (None, None, None, 2 0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, None, None, 1 262144      res4c_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4c (Add)                     (None, None, None, 1 0           bn4c_branch2c[0][0]              \n",
            "                                                                 res4b_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4c_relu (Activation)         (None, None, None, 1 0           res4c[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, None, None, 2 262144      res4c_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a_relu (Activation (None, None, None, 2 0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding4d_branch2b (ZeroPadding (None, None, None, 2 0           res4d_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, None, None, 2 589824      padding4d_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b_relu (Activation (None, None, None, 2 0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, None, None, 1 262144      res4d_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4d (Add)                     (None, None, None, 1 0           bn4d_branch2c[0][0]              \n",
            "                                                                 res4c_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4d_relu (Activation)         (None, None, None, 1 0           res4d[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, None, None, 2 262144      res4d_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a_relu (Activation (None, None, None, 2 0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding4e_branch2b (ZeroPadding (None, None, None, 2 0           res4e_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, None, None, 2 589824      padding4e_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b_relu (Activation (None, None, None, 2 0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, None, None, 1 262144      res4e_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4e (Add)                     (None, None, None, 1 0           bn4e_branch2c[0][0]              \n",
            "                                                                 res4d_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4e_relu (Activation)         (None, None, None, 1 0           res4e[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, None, None, 2 262144      res4e_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a_relu (Activation (None, None, None, 2 0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding4f_branch2b (ZeroPadding (None, None, None, 2 0           res4f_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, None, None, 2 589824      padding4f_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b_relu (Activation (None, None, None, 2 0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, None, None, 1 262144      res4f_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4f (Add)                     (None, None, None, 1 0           bn4f_branch2c[0][0]              \n",
            "                                                                 res4e_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4f_relu (Activation)         (None, None, None, 1 0           res4f[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, None, None, 5 524288      res4f_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, None, None, 5 2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a_relu (Activation (None, None, None, 5 0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding5a_branch2b (ZeroPadding (None, None, None, 5 0           res5a_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, None, None, 5 2359296     padding5a_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, None, None, 5 2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b_relu (Activation (None, None, None, 5 0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, None, None, 2 1048576     res5a_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, None, None, 2 2097152     res4f_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, None, None, 2 8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, None, None, 2 8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a (Add)                     (None, None, None, 2 0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res5a_relu (Activation)         (None, None, None, 2 0           res5a[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, None, None, 5 1048576     res5a_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, None, None, 5 2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a_relu (Activation (None, None, None, 5 0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding5b_branch2b (ZeroPadding (None, None, None, 5 0           res5b_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, None, None, 5 2359296     padding5b_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, None, None, 5 2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b_relu (Activation (None, None, None, 5 0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, None, None, 2 1048576     res5b_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, None, None, 2 8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5b (Add)                     (None, None, None, 2 0           bn5b_branch2c[0][0]              \n",
            "                                                                 res5a_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res5b_relu (Activation)         (None, None, None, 2 0           res5b[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, None, None, 5 1048576     res5b_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, None, None, 5 2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a_relu (Activation (None, None, None, 5 0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding5c_branch2b (ZeroPadding (None, None, None, 5 0           res5c_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, None, None, 5 2359296     padding5c_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, None, None, 5 2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b_relu (Activation (None, None, None, 5 0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, None, None, 2 1048576     res5c_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, None, None, 2 8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5c (Add)                     (None, None, None, 2 0           bn5c_branch2c[0][0]              \n",
            "                                                                 res5b_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res5c_relu (Activation)         (None, None, None, 2 0           res5c[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "C5_reduced (Conv2D)             (None, None, None, 2 524544      res5c_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "P5_upsampled (UpsampleLike)     (None, None, None, 2 0           C5_reduced[0][0]                 \n",
            "                                                                 res4f_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "C4_reduced (Conv2D)             (None, None, None, 2 262400      res4f_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "P4_merged (Add)                 (None, None, None, 2 0           P5_upsampled[0][0]               \n",
            "                                                                 C4_reduced[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "P4_upsampled (UpsampleLike)     (None, None, None, 2 0           P4_merged[0][0]                  \n",
            "                                                                 res3d_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "C3_reduced (Conv2D)             (None, None, None, 2 131328      res3d_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "P6 (Conv2D)                     (None, None, None, 2 4718848     res5c_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "P3_merged (Add)                 (None, None, None, 2 0           P4_upsampled[0][0]               \n",
            "                                                                 C3_reduced[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "C6_relu (Activation)            (None, None, None, 2 0           P6[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "P3 (Conv2D)                     (None, None, None, 2 590080      P3_merged[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "P4 (Conv2D)                     (None, None, None, 2 590080      P4_merged[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "P5 (Conv2D)                     (None, None, None, 2 590080      C5_reduced[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "P7 (Conv2D)                     (None, None, None, 2 590080      C6_relu[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "regression_submodel (Functional (None, None, 4)      2443300     P3[0][0]                         \n",
            "                                                                 P4[0][0]                         \n",
            "                                                                 P5[0][0]                         \n",
            "                                                                 P6[0][0]                         \n",
            "                                                                 P7[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "classification_submodel (Functi (None, None, 2)      2401810     P3[0][0]                         \n",
            "                                                                 P4[0][0]                         \n",
            "                                                                 P5[0][0]                         \n",
            "                                                                 P6[0][0]                         \n",
            "                                                                 P7[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "regression (Concatenate)        (None, None, 4)      0           regression_submodel[0][0]        \n",
            "                                                                 regression_submodel[1][0]        \n",
            "                                                                 regression_submodel[2][0]        \n",
            "                                                                 regression_submodel[3][0]        \n",
            "                                                                 regression_submodel[4][0]        \n",
            "__________________________________________________________________________________________________\n",
            "classification (Concatenate)    (None, None, 2)      0           classification_submodel[0][0]    \n",
            "                                                                 classification_submodel[1][0]    \n",
            "                                                                 classification_submodel[2][0]    \n",
            "                                                                 classification_submodel[3][0]    \n",
            "                                                                 classification_submodel[4][0]    \n",
            "==================================================================================================\n",
            "Total params: 36,403,702\n",
            "Trainable params: 36,297,462\n",
            "Non-trainable params: 106,240\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From keras-retinanet/keras_retinanet/bin/train.py:604: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/50\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 986, in func_graph_from_py_func\n",
            "    func_outputs = python_func(*func_args, **func_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 600, in wrapped_fn\n",
            "    return weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 969, in wrapper\n",
            "    user_requested=True,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 596, in converted_call\n",
            "    result = converted_f(*effective_args, **kwargs)\n",
            "  File \"/tmp/tmpvj3dz5_e.py\", line 16, in tf__train_function\n",
            "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 457, in converted_call\n",
            "    return _call_unconverted(f, args, kwargs, options, False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 340, in _call_unconverted\n",
            "    return f(*args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 796, in step_function\n",
            "    outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 1211, in run\n",
            "    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 2585, in call_for_each_replica\n",
            "    return self._call_for_each_replica(fn, args, kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 2945, in _call_for_each_replica\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 255, in wrapper\n",
            "    return converted_call(f, args, kwargs, options=options)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 532, in converted_call\n",
            "    return _call_unconverted(f, args, kwargs, options)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 339, in _call_unconverted\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 789, in run_step\n",
            "    outputs = model.train_step(data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 747, in train_step\n",
            "    y_pred = self(x, training=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 985, in __call__\n",
            "    outputs = call_fn(inputs, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\", line 386, in call\n",
            "    inputs, training=training, mask=mask)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\", line 508, in _run_internal_graph\n",
            "    outputs = node.layer(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 985, in __call__\n",
            "    outputs = call_fn(inputs, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 255, in wrapper\n",
            "    return converted_call(f, args, kwargs, options=options)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 596, in converted_call\n",
            "    result = converted_f(*effective_args, **kwargs)\n",
            "  File \"/tmp/tmp2ffwkmpu.py\", line 26, in tf__call\n",
            "    retval_ = ag__.converted_call(ag__.converted_call(ag__.ld(super), (ag__.ld(BatchNormalization), ag__.ld(self)), None, fscope).call, tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 457, in converted_call\n",
            "    return _call_unconverted(f, args, kwargs, options, False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 339, in _call_unconverted\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/normalization.py\", line 720, in call\n",
            "    outputs = self._fused_batch_norm(inputs, training=training)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/normalization.py\", line 577, in _fused_batch_norm\n",
            "    _fused_batch_norm_inference)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\", line 65, in smart_cond\n",
            "    pred, true_fn=true_fn, false_fn=false_fn, name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/smart_cond.py\", line 56, in smart_cond\n",
            "    return false_fn()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/normalization.py\", line 566, in _fused_batch_norm_inference\n",
            "    data_format=self._data_format)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\", line 201, in wrapper\n",
            "    return target(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_impl.py\", line 1647, in fused_batch_norm\n",
            "    name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 4297, in fused_batch_norm_v3\n",
            "    name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 470, in _apply_op_helper\n",
            "    preferred_dtype=default_dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1499, in convert_to_tensor\n",
            "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1909, in _dense_var_to_tensor\n",
            "    return var._dense_var_to_tensor(dtype=dtype, name=name, as_ref=as_ref)  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1326, in _dense_var_to_tensor\n",
            "    return self.value()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 555, in value\n",
            "    return self._read_variable_op()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 657, in _read_variable_op\n",
            "    result = read_and_set_handle()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 648, in read_and_set_handle\n",
            "    self._dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 491, in read_variable_op\n",
            "    \"ReadVariableOp\", resource=resource, dtype=dtype, name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 470, in _apply_op_helper\n",
            "    preferred_dtype=default_dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1467, in convert_to_tensor\n",
            "    return graph.capture(value, name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 627, in capture\n",
            "    return self._capture_helper(tensor, name, shape)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 648, in _capture_helper\n",
            "    tensor, name=name, dtype=tensor.dtype, shape=shape)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 1131, in _create_substitute_placeholder\n",
            "    dtype=dtype or value.dtype, shape=shape, name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/graph_only_ops.py\", line 40, in graph_placeholder\n",
            "    attrs=attrs, name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 593, in _create_op_internal\n",
            "    compute_device)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 3470, in _create_op_internal\n",
            "    node_def = _NodeDef(op_type, name, attrs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1754, in _NodeDef\n",
            "    node_def.attr[k].CopyFrom(v)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"keras-retinanet/keras_retinanet/bin/train.py\", line 609, in <module>\n",
            "    main()\n",
            "  File \"keras-retinanet/keras_retinanet/bin/train.py\", line 604, in main\n",
            "    initial_epoch=args.initial_epoch\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 1829, in fit_generator\n",
            "    initial_epoch=initial_epoch)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\n",
            "    return method(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 1098, in fit\n",
            "    tmp_logs = train_function(iterator)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 840, in _call\n",
            "    return self._stateless_fn(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 2828, in __call__\n",
            "    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3213, in _maybe_define_function\n",
            "    graph_function = self._create_graph_function(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3075, in _create_graph_function\n",
            "    capture_by_value=self._capture_by_value),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 1027, in func_graph_from_py_func\n",
            "    func_graph.variables = variables\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/auto_control_deps.py\", line 398, in __exit__\n",
            "    for inp, resource_type in _get_resource_inputs(op):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/auto_control_deps.py\", line 521, in _get_resource_inputs\n",
            "    reads, writes = utils.get_read_write_resource_inputs(op)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/auto_control_deps_utils.py\", line 109, in get_read_write_resource_inputs\n",
            "    read_only_input_indices = op.get_attr(READ_ONLY_RESOURCE_INPUTS_ATTR)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 2486, in get_attr\n",
            "    pywrap_tf_session.TF_OperationGetAttrValueProto(self._c_op, name, buf)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 267, in __init__\n",
            "    INVALID_ARGUMENT)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 74, in __init__\n",
            "    super(OpError, self).__init__()\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28P8eyNJ2BnO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "c191fc0c-d603-4921-e1a9-559f9d2d35d6"
      },
      "source": [
        "list_of_files = glob.glob('snapshots/resnet*.h5')\n",
        "latest_file = max(list_of_files, key=os.path.getctime)\n",
        "epoch_final = latest_file[latest_file.index(\"_csv_\")+5:-3]\n",
        "best_model_training = latest_file.replace(\"/content/\", \"\")\n",
        "print(best_model_training)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-d0da4696ad36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlist_of_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'snapshots/resnet*.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlatest_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetctime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mepoch_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatest_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlatest_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_csv_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbest_model_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatest_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apHCQjSo8WC2"
      },
      "source": [
        "This next section converts the model from training mode to inference mode so it can be used to detect our target objects (seals). Until now we've been updating the model based on its performance; now we're fixing the model in a static \"snapshot\" so we can test it out. This conversion process take a little time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YyMralKEKuz"
      },
      "source": [
        "# note that we are naming our model \"best_model_inference\" and locating it in the \"snapshots\" directory. Customize if wanted\n",
        "model_name = \"best_model_inference\"\n",
        "#! keras-retinanet/keras_retinanet/bin/convert_model.py snapshots/resnet50_csv_10.h5 snapshots/best_model_inference.h5\n",
        "subprocess.run([\"keras-retinanet/keras_retinanet/bin/convert_model.py\", best_model_training, \"snapshots/{m}.h5\".format(m=model_name)])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu3yk48fEKu2"
      },
      "source": [
        "### Run Detection in inference mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbTLLmbGEKu2"
      },
      "source": [
        "This section sets up the environment, importing modules for python tasks and specific to keras+retinanet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj-WmUXiEKu3"
      },
      "source": [
        "# show images inline\n",
        "%matplotlib inline\n",
        "\n",
        "# automatically reload modules when they have changed\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# import keras\n",
        "import keras\n",
        "\n",
        "# import keras_retinanet\n",
        "from keras_retinanet import models\n",
        "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
        "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
        "from keras_retinanet.utils.colors import label_color\n",
        "\n",
        "# import miscellaneous modules\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import json\n",
        "from random import shuffle\n",
        "\n",
        "# set tf backend to allow memory to grow, instead of claiming everything\n",
        "import tensorflow as tf\n",
        "\n",
        "def get_session():\n",
        "    config = tf.compat.v1.ConfigProto()    \n",
        "    config.gpu_options.allow_growth = True\n",
        "    return tf.compat.v1.Session(config=config)\n",
        "\n",
        "# use this environment flag to change which GPU to use\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "# set the modified tf session as backend in keras\n",
        "tf.compat.v1.keras.backend.set_session(get_session())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w987GUwIEKu5"
      },
      "source": [
        "### Load RetinaNet model\n",
        "\n",
        "Now we will load the model that you just converted into inference mode: by default it is called `test_model.h5`, but you might have renamed your model_name variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDo883mYEKu6"
      },
      "source": [
        "model_path = 'snapshots/{m}.h5'.format(m=model_name)\n",
        "\n",
        "print(model_path)\n",
        "\n",
        "# load retinanet model\n",
        "model = models.load_model(model_path, backbone_name='resnet50')\n",
        "\n",
        "# you can check out a model summary by uncommenting this line\n",
        "#print(model.summary())\n",
        "\n",
        "# load label to names mapping for visualization purposes\n",
        "# pull labels from classes.csv\n",
        "import csv\n",
        "with open(classes_file, \"r\") as f:\n",
        "    reader = csv.reader(f, delimiter=\",\")\n",
        "    labels_to_names = {int(i[1]):i[0] for i in reader}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jfMnDLVEKu9"
      },
      "source": [
        "### Load test imagery\n",
        "\n",
        "Now we will load the \"testing\" subset of images that we downloaded into our data directory during setup (as listed in the subsets CSV file). Just to check, we'll print out the first five names of those images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QjtUN5wEKu9"
      },
      "source": [
        "# load imagery\n",
        "image_dir = \"data/\"\n",
        "\n",
        "# this code pulls only files from the test or validation subset\n",
        "# as specified in this variable, \"target_subset\" either \"test\" or \"validation\"\n",
        "target_subset = \"testing\"\n",
        "\n",
        "image_list = []\n",
        "with open(subset_list_file, \"r\") as f:\n",
        "    reader = csv.reader(f, delimiter=\",\")\n",
        "    for i in reader:\n",
        "      if i[1] == target_subset:\n",
        "        image_list.append(image_dir + i[0])\n",
        "print(image_list[:5])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "detiYRZWEKvA"
      },
      "source": [
        "### Test out detections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDezuFxm-xAf"
      },
      "source": [
        "Now we'll visualize some detections from our model to see how it performs. Each detection has a \"confidence score\" that describes the CNN's confidence that the detection is correct. Change the minimum confidence score (the first line of code) and re-run the code to check out how your \"confidence threshold\" affects the numbers of false positives and false negatives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I13IyhvEKvA"
      },
      "source": [
        "min_score = 0.4 # this is the CNN's confidence that the detection is correct\n",
        "detection_iterations = 10 # max number of images to visualize\n",
        "\n",
        "visualize = True\n",
        "\n",
        "detections = {}\n",
        "\n",
        "total_time = 0\n",
        "\n",
        "count = 0\n",
        "shuffle(image_list)\n",
        "\n",
        "for image_path in image_list:\n",
        "    if count > detection_iterations:\n",
        "        break\n",
        "    else:\n",
        "        count +=1\n",
        "        \n",
        "    image = read_image_bgr(image_path)\n",
        "\n",
        "    if visualize:\n",
        "        # copy to draw on\n",
        "        draw = image.copy()\n",
        "        draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # preprocess image for network\n",
        "    image = preprocess_image(image)\n",
        "    image, scale = resize_image(image)\n",
        "\n",
        "    # process image\n",
        "    start = time.time()\n",
        "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
        "    total_time += time.time() - start\n",
        "\n",
        "    # correct for image scale\n",
        "    boxes /= scale\n",
        "    if any(score >= min_score for score in scores[0]):\n",
        "        detections[image_path] = []\n",
        "\n",
        "    # visualize detections\n",
        "    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
        "        # scores are sorted so we can break\n",
        "        if score < min_score:\n",
        "            break\n",
        "\n",
        "        #print(score)\n",
        "        #print(box)\n",
        "\n",
        "        # TODO this does create a slight error in the boxes, might be worth doing something like\n",
        "        # list(map(str, box) but then would need to cast on the other end back to float\n",
        "        b = box.astype(int)\n",
        "        detections[image_path].append({\"box\" : b, \"label\" : label, \"score\" : score})\n",
        "\n",
        "        if visualize:\n",
        "            color = label_color(label)\n",
        "\n",
        "            # b = box.astype(int)\n",
        "            draw_box(draw, b, color=color)\n",
        "\n",
        "            caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
        "            draw_caption(draw, b, caption)\n",
        "\n",
        "    if any(score >= min_score for score in scores[0]):\n",
        "        if visualize:\n",
        "            plt.figure(figsize=(10, 10))\n",
        "            plt.axis('off')\n",
        "            plt.imshow(draw)\n",
        "            plt.show()\n",
        "    \n",
        "print(\"Finished, time per image:\", total_time/len(image_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_Khk5BWEKvD"
      },
      "source": [
        "### Run Detections on all tiles\n",
        "This section repeats the process we just tested for all tiles that make up our orthomosaic. If you want to experiment, you can vary the confidence threshold and the amount of time the model trains, then look at how it affects the resulting detections.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Tvuim_vEKvE"
      },
      "source": [
        "visualize = False\n",
        "min_score = min_score # this is the CNN's confidence that the detection is correct\n",
        "\n",
        "detections = {}\n",
        "\n",
        "total_time = 0\n",
        "\n",
        "for image_path in image_list:\n",
        "       \n",
        "    image = read_image_bgr(image_path)\n",
        "\n",
        "    if visualize:\n",
        "        # copy to draw on\n",
        "        draw = image.copy()\n",
        "        draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # preprocess image for network\n",
        "    image = preprocess_image(image)\n",
        "    image, scale = resize_image(image)\n",
        "\n",
        "    # process image\n",
        "    start = time.time()\n",
        "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
        "    total_time += time.time() - start\n",
        "\n",
        "    # correct for image scale\n",
        "    boxes /= scale\n",
        "    if any(score >= min_score for score in scores[0]):\n",
        "        detections[image_path] = []\n",
        "\n",
        "    # visualize detections\n",
        "    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
        "        # scores are sorted so we can break\n",
        "        if score < min_score:\n",
        "            break\n",
        "\n",
        "        #print(score)\n",
        "        #print(box)\n",
        "\n",
        "        # TODO this does create a slight error in the boxes, might be worth doing something like\n",
        "        # list(map(str, box) but then would need to cast on the other end back to float\n",
        "        b = box.astype(int)\n",
        "        detections[image_path].append({\"box\" : b, \"label\" : label, \"score\" : score})\n",
        "\n",
        "        if visualize:\n",
        "            color = label_color(label)\n",
        "\n",
        "            # b = box.astype(int)\n",
        "            draw_box(draw, b, color=color)\n",
        "\n",
        "            caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
        "            draw_caption(draw, b, caption)\n",
        "\n",
        "    if any(score >= min_score for score in scores[0]):\n",
        "        if visualize:\n",
        "            plt.figure(figsize=(10, 10))\n",
        "            plt.axis('off')\n",
        "            plt.imshow(draw)\n",
        "            plt.show()\n",
        "    \n",
        "print(\"Finished, time per image:\", total_time/len(image_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P3nBtjv81_J"
      },
      "source": [
        "Run an evaluation script to get the mean average precision (mAP) of the CNN. \n",
        "\n",
        "mAP is a model evaluation metric that is relative (aka it can be challenging to compare mAP values across datasets), but a great general metric for different models and approaches to detection objects on the same dataset. \n",
        "\n",
        "Read more about mAP here: https://tarangshah.com/blog/2018-01-27/what-is-map-understanding-the-statistic-of-choice-for-comparing-object-detection-models/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CKEvUTb1JC0"
      },
      "source": [
        "#! keras-retinanet/keras_retinanet/bin/evaluate.py csv data/annotations_test.csv data/classes.csv snapshots/test_model.h5\n",
        "\n",
        "precision_metrics = subprocess.check_output(['keras-retinanet/keras_retinanet/bin/evaluate.py', 'csv', testing_data_file, classes_file, model_path]).decode(\"utf-8\")\n",
        "model_summary = str('Model {m} was generated using {e} epochs, {s} steps and {b} batches'.format(m=model_name, e=epoch_final, s=step_number, b=batch_size_number))\n",
        "print(model_summary)\n",
        "print(precision_metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SyoUJ6REKvJ"
      },
      "source": [
        "### Export detections##\n",
        "Write out the detections to a json file that can be used in a GIS for  spatial databases and/or visualizations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-zIVPAVEKvH"
      },
      "source": [
        "class MyEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.integer):\n",
        "            return int(obj)\n",
        "        elif isinstance(obj, np.floating):\n",
        "            return float(obj)\n",
        "        elif isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        else:\n",
        "            return super(MyEncoder, self).default(obj)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd3NXa3wEKvK"
      },
      "source": [
        "output_file_name = 'data/new_detections.json'\n",
        "with open(output_file_name, 'w') as fp:\n",
        "    json.dump(detections, fp, cls=MyEncoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-6WjaR1EKvM"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/\" + output_file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgDzXkfvcOhk"
      },
      "source": [
        "### Export model and metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8ndsVTJcOhl"
      },
      "source": [
        "# export metrics (fast)\n",
        "files.download(\"/content/output/Epoch-{n}.png\".format(n=epoch_final))\n",
        "files.download(\"/content/output/Epoch-{n}.csv\".format(n=epoch_final))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1lQjgH6Sy5z"
      },
      "source": [
        "#export model (slow)\n",
        "files.download(\"/content/{m}\".format(m=model_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ24IwaycOhl"
      },
      "source": [
        "#### At the end of this script you should have a single JSON file downloaded (in addition model training metrics in `png` and `csv` format, and the model, if you exported it). Drop this in the Google Drive folder so it can be exported in the next step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ3OzkdicOhm"
      },
      "source": [
        "Next steps:\n",
        "\n",
        "5) export CNN outputs"
      ]
    }
  ]
}