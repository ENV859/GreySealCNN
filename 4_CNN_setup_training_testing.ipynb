{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN_training_testing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f0nIhYPcOgi"
      },
      "source": [
        "# Set up the CNN + model, Train it and Test it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwHi5FI7cOhG"
      },
      "source": [
        "**Before running this script, make sure that your Google Drive folder contains the tiles you created, the `tiling_scheme.json` file (`step 1`), and the 5 `csv` files that you created (`step 3`) to describe: the 3 data subsets (1 `csv` file), the annotations for each (3 `csv` files) and the class list (1 `csv` file).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gl7176/GreySealCNN/blob/master/4_CNN_setup_training_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "#####  <center> Be sure to update this hyperlink above if you clone and want to point to a different GitHub </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XElcTShEQkh"
      },
      "source": [
        "### Connect to our Google Drive folder and pull all data\n",
        "Note: when you run this it will give you a link that you must click. You must give Google some permissions, then copy a code into a box that comes up in the output section of this code.\n",
        "\n",
        "If customizing this code, you will need to point the `drive_folder` variable to a URL for your shared google drive folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le3bfsAjzSP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "510e5c79-eea8-4c7f-c9bd-f940ed041670"
      },
      "source": [
        "# set variable to the destination google drive folder you want to pull from\n",
        "drive_folder = 'https://drive.google.com/drive/folders/1INuRNVKvKMy8L_Nb6lmoVbyvScWK0-0D'\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# choose a local (colab) directory to store the data.\n",
        "local_download_path = os.path.expanduser('data')\n",
        "try:\n",
        "  os.makedirs(local_download_path)\n",
        "except: pass\n",
        "\n",
        "# 2. Auto-iterate using the query syntax\n",
        "#    https://developers.google.com/drive/v2/web/search-parameters\n",
        "\n",
        "# this bit points the code to that google drive folder\n",
        "pointer = str(\"'\" + drive_folder.split(\"/\")[-1] + \"'\" + \" in parents\")\n",
        "\n",
        "file_list = drive.ListFile(\n",
        "    {'q': pointer}).GetList()\n",
        "\n",
        "#    this bit pulls every file in the directory specified above\n",
        "image_list = []\n",
        "count = 0\n",
        "for f in file_list:\n",
        "  fname = os.path.join(local_download_path, f['title'])\n",
        "  if fname.endswith(\".png\"):\n",
        "    image_list.append(fname.split(\"/\")[1])\n",
        "    count += 1\n",
        "    if count % 10 == 0:\n",
        "      print(str(count) + \" tiles pulled\")\n",
        "  # 3. Create & download by id.\n",
        "  f_ = drive.CreateFile({'id': f['id']})\n",
        "  f_.GetContentFile(fname)\n",
        "  if fname.endswith(\".csv\") or fname.endswith(\".json\"):\n",
        "    print(\"Pulled file: \" + fname)\n",
        "print(str(count) + \" tiles pulled\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pulled file: data/tiling_scheme.json\n",
            "Pulled file: data/new_detections.json\n",
            "Pulled file: data/classes.csv\n",
            "Pulled file: data/annotations_train.csv\n",
            "Pulled file: data/annotations_test.csv\n",
            "Pulled file: data/subset_list.csv\n",
            "Pulled file: data/annotations_valid.csv\n",
            "Pulled file: data/via_SealCNN_TrainingData.csv\n",
            "10 tiles pulled\n",
            "20 tiles pulled\n",
            "30 tiles pulled\n",
            "40 tiles pulled\n",
            "50 tiles pulled\n",
            "60 tiles pulled\n",
            "70 tiles pulled\n",
            "80 tiles pulled\n",
            "90 tiles pulled\n",
            "100 tiles pulled\n",
            "110 tiles pulled\n",
            "120 tiles pulled\n",
            "130 tiles pulled\n",
            "140 tiles pulled\n",
            "150 tiles pulled\n",
            "160 tiles pulled\n",
            "170 tiles pulled\n",
            "180 tiles pulled\n",
            "190 tiles pulled\n",
            "200 tiles pulled\n",
            "210 tiles pulled\n",
            "220 tiles pulled\n",
            "230 tiles pulled\n",
            "240 tiles pulled\n",
            "244 tiles pulled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVqZgStvmrrI"
      },
      "source": [
        "### Identify necessary files from the input directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAvrvhCUmsZn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd0743cb-453e-4f83-8f1b-7a1799a71ed7"
      },
      "source": [
        "import csv, json, glob\n",
        "\n",
        "# use this variable to set input directory\n",
        "input_dir = local_download_path\n",
        "\n",
        "training_data_file = 'annotations_train.csv'\n",
        "testing_data_file = 'annotations_test.csv'\n",
        "validation_data_file = 'annotations_valid.csv'\n",
        "classes_file = 'classes.csv'\n",
        "subset_list_file = 'subset_list.csv'\n",
        "tiling_scheme_file = 'tiling_scheme_placeholder'\n",
        "\n",
        "checklist = {training_data_file:\"training_data_file\", testing_data_file:\"testing_data_file\", \n",
        "             validation_data_file:\"validation_data_file\", classes_file:\"classes_file\",\n",
        "             subset_list_file:\"subset_list_file\", tiling_scheme_file:\"tiling_scheme_file\"}\n",
        "\n",
        "for fname in os.listdir(input_dir):\n",
        "  if fname.endswith(\".csv\"): \n",
        "    try: \n",
        "      vars()[checklist[fname]] = \"{i}/{f}\".format(i=input_dir, f=fname)\n",
        "      print(\"required file found: {v}\".format(v=vars()[checklist[fname]]))\n",
        "      del checklist[fname]\n",
        "    except: print(\"{f} detected but not listed among requirements\".format(f=fname))\n",
        "  if fname.endswith(\".json\"):\n",
        "    tiling_scheme_candidate = \"{i}/{f}\".format(i=input_dir, f=fname)\n",
        "    with open(tiling_scheme_candidate) as f:\n",
        "      try:\n",
        "        tile_list = json.load(f)[\"tile_pointers\"][\"image_locations\"]\n",
        "        tiling_scheme_file = tiling_scheme_candidate\n",
        "        print(\"required file found: {s}\".format(s=tiling_scheme_file))\n",
        "        del checklist['tiling_scheme_placeholder']\n",
        "      except: \n",
        "        print(\"{f} detected but not listed among requirements\".format(f=fname))\n",
        "\n",
        "if len(checklist) > 0:\n",
        "  for key in checklist:\n",
        "    print(\"Error: did not find {k} in your input folder\".format(k=key))\n",
        "  raise Exception(\"missing specified data files\")\n",
        "  \n",
        "# confirm that all files in tiling_scheme_file were pulled from Google Drive\n",
        "if len(tile_list) != len(image_list):\n",
        "  print('Step one produced {n1} tiles, but google drive contained {n2} images. Confirm that tile set is complete.\\n'.format(n1=len(tile_list), n2=len(image_list)))\n",
        "  raise Exception(\"tile count mismatch\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "required file found: data/annotations_test.csv\n",
            "required file found: data/annotations_valid.csv\n",
            "required file found: data/subset_list.csv\n",
            "required file found: data/tiling_scheme.json\n",
            "required file found: data/classes.csv\n",
            "required file found: data/annotations_train.csv\n",
            "via_SealCNN_TrainingData.csv detected but not listed among requirements\n",
            "new_detections.json detected but not listed among requirements\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-xdfna11L2F"
      },
      "source": [
        "### Install the Convolutional Neural Network that will do the detections. \n",
        "\n",
        "This section sets up the software and pulls code for a CNN model called \"RetinaNet\" which uses the model \"ResNet-50\" as a subcomponent. This section then loads data for an existing ResNet-50 model (pre-trained for object detection) which we will further train for our task.\n",
        "\n",
        "Disregard any errors or prompts to \"restart runtime\" unless the code stops progressing (then email me at gdl10@duke.edu)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-VXXOfd-LXa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2eff1777-ae84-4be2-bdc8-f5a172a2215e"
      },
      "source": [
        "# clear colab's current versions\n",
        "!pip uninstall -y keras\n",
        "!pip uninstall -y keras-nightly\n",
        "!pip uninstall -y tensorflow\n",
        "!pip install h5py==2.10.0  \n",
        "\n",
        "# install the keras package we need\n",
        "!pip3 install keras==2.4.3\n",
        "# install the TF version we need\n",
        "!pip3 uninstall tensorflow -y\n",
        "!pip3 install tensorflow==2.3.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling Keras-2.4.3:\n",
            "  Successfully uninstalled Keras-2.4.3\n",
            "Uninstalling keras-nightly-2.5.0.dev2021032900:\n",
            "  Successfully uninstalled keras-nightly-2.5.0.dev2021032900\n",
            "Uninstalling tensorflow-2.5.0:\n",
            "  Successfully uninstalled tensorflow-2.5.0\n",
            "Collecting h5py==2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 9.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "\u001b[31mERROR: keras-vis 0.4.1 requires keras, which is not installed.\u001b[0m\n",
            "Installing collected packages: h5py\n",
            "  Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed h5py-2.10.0\n",
            "Collecting keras==2.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/44/e1/dc0757b20b56c980b5553c1b5c4c32d378c7055ab7bfa92006801ad359ab/Keras-2.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.4.3) (1.15.0)\n",
            "Installing collected packages: keras\n",
            "Successfully installed keras-2.4.3\n",
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n",
            "Collecting tensorflow==2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/89/f2d29c2eafc2eeafb17d5634340e06366af904d332341200a49d954bce85/tensorflow-2.3.0-cp37-cp37m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 47kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.12.1)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.4.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.34.1)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (2.5.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.1.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (2.10.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.6.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.36.2)\n",
            "Collecting numpy<1.19.0,>=1.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/c6/58e517e8b1fb192725cfa23c01c2e60e4e6699314ee9684a1c5f5c9b27e1/numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 164kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.4.0,>=2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/ed/5853ec0ae380cba4588eab1524e18ece1583b65f7ae0e97321f5ff9dfd60/tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 45.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.1.2)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (3.12.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.31.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (57.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.2.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.1.1)\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, tensorflow-estimator, gast, tensorflow\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "Successfully installed gast-0.3.3 numpy-1.18.5 tensorflow-2.3.0 tensorflow-estimator-2.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jb7YRXlEUUg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f443d91e-ff1a-4e10-a4a9-332130e714e6"
      },
      "source": [
        "# copy the files for RetinaNet\n",
        "# note that this build is now deprecated, but we are fine with that\n",
        "# now pulling from a personal clone that outputs error metrics\n",
        "! git clone https://github.com/gl7176/keras-retinanet.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-retinanet'...\n",
            "remote: Enumerating objects: 6236, done.\u001b[K\n",
            "remote: Total 6236 (delta 0), reused 0 (delta 0), pack-reused 6236\u001b[K\n",
            "Receiving objects: 100% (6236/6236), 13.48 MiB | 23.71 MiB/s, done.\n",
            "Resolving deltas: 100% (4221/4221), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuULO44w6yx8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3e39879-44ec-44d8-b043-8ba168b108a1"
      },
      "source": [
        "# change directory and install RetinaNet from the copied code\n",
        "% cd keras-retinanet\n",
        "\n",
        "! pip install ."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras-retinanet\n",
            "Processing /content/keras-retinanet\n",
            "Collecting keras-resnet==0.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/76/d4/a35cbd07381139dda4db42c81b88c59254faac026109022727b45b31bcad/keras-resnet-0.2.0.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==1.0.0) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==1.0.0) (1.18.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==1.0.0) (0.29.23)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==1.0.0) (7.1.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==1.0.0) (4.1.2.30)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==1.0.0) (3.38.0)\n",
            "Requirement already satisfied: keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from keras-resnet==0.2.0->keras-retinanet==1.0.0) (2.4.3)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from progressbar2->keras-retinanet==1.0.0) (2.5.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (3.13)\n",
            "Building wheels for collected packages: keras-retinanet, keras-resnet\n",
            "  Building wheel for keras-retinanet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-retinanet: filename=keras_retinanet-1.0.0-cp37-cp37m-linux_x86_64.whl size=169805 sha256=86ea3321e4735b24743f3dfe1c59a28e8b133b353aac6c0e7d75f9cdaf97504f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/9f/57/cb0305f6f5a41fc3c11ad67b8cedfbe9127775b563337827ba\n",
            "  Building wheel for keras-resnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-resnet: filename=keras_resnet-0.2.0-py2.py3-none-any.whl size=20487 sha256=f211f9812240966fe6bc6d60bd0381187159a9cf4c53bae45d151d61095f557a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/09/a5/497a30fd9ad9964e98a1254d1e164bcd1b8a5eda36197ecb3c\n",
            "Successfully built keras-retinanet keras-resnet\n",
            "Installing collected packages: keras-resnet, keras-retinanet\n",
            "Successfully installed keras-resnet-0.2.0 keras-retinanet-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu_IOPbC44SC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15e70647-2ff7-4c62-ba3c-990586639f58"
      },
      "source": [
        "! python setup.py build_ext --inplace"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running build_ext\n",
            "cythoning keras_retinanet/utils/compute_overlap.pyx to keras_retinanet/utils/compute_overlap.c\n",
            "/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/keras-retinanet/keras_retinanet/utils/compute_overlap.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "building 'keras_retinanet.utils.compute_overlap' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/keras_retinanet\n",
            "creating build/temp.linux-x86_64-3.7/keras_retinanet/utils\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.7m -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -c keras_retinanet/utils/compute_overlap.c -o build/temp.linux-x86_64-3.7/keras_retinanet/utils/compute_overlap.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1832:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kkeras_retinanet/utils/compute_overlap.c:612\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/keras_retinanet\n",
            "creating build/lib.linux-x86_64-3.7/keras_retinanet/utils\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/keras_retinanet/utils/compute_overlap.o -o build/lib.linux-x86_64-3.7/keras_retinanet/utils/compute_overlap.cpython-37m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.7/keras_retinanet/utils/compute_overlap.cpython-37m-x86_64-linux-gnu.so -> keras_retinanet/utils\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33S3M0SoI1JI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "578c39f1-dadb-42e6-a775-65c3b0664152"
      },
      "source": [
        "% cd ../\n",
        "\n",
        "# get the pre-trained ResNet-50 model\n",
        "! wget -P data \"https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "--2021-07-02 21:28:35--  https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/100249425/b7184a80-9350-11e9-9cc2-454f5c616394?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210702%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210702T212835Z&X-Amz-Expires=300&X-Amz-Signature=a3596192f759ef14fced39a95505dd4403c38ed42ba8cab03ea972f056ea2995&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=100249425&response-content-disposition=attachment%3B%20filename%3Dresnet50_coco_best_v2.1.0.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-07-02 21:28:35--  https://github-releases.githubusercontent.com/100249425/b7184a80-9350-11e9-9cc2-454f5c616394?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210702%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210702T212835Z&X-Amz-Expires=300&X-Amz-Signature=a3596192f759ef14fced39a95505dd4403c38ed42ba8cab03ea972f056ea2995&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=100249425&response-content-disposition=attachment%3B%20filename%3Dresnet50_coco_best_v2.1.0.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 152662144 (146M) [application/octet-stream]\n",
            "Saving to: ‘data/resnet50_coco_best_v2.1.0.h5’\n",
            "\n",
            "resnet50_coco_best_ 100%[===================>] 145.59M  58.3MB/s    in 2.5s    \n",
            "\n",
            "2021-07-02 21:28:38 (58.3 MB/s) - ‘data/resnet50_coco_best_v2.1.0.h5’ saved [152662144/152662144]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYBUnE6wEKuq"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzdoAR2GEKuv"
      },
      "source": [
        "We're giving our model the pre-trained weights that we downloaded above, and then we're telling it to use the `training_data_file`, to run with hyper-parameters `epoch_number` and `batch_size_number`.\n",
        "\n",
        "An epoch is a group of steps after which the model calculates its accuracy; the epoch parameter is the maximum number the training will run before stopping; in this framework the model will stop running once it stops improving (based on mAP) for multiple epochs, determined by a 'patience' variable (here, 5).\n",
        "\n",
        "A step is an increment of training the model on one batch or subset of files. The step size is limited on the upper bound by the training data (divided into batches), which we calculate in the code.\n",
        "\n",
        "A batch is the number of images being analyzed in each step. Batch-size is functionally limited by RAM (how many images the computer can store in memory), and given our default tile size, Colab runs out of memory at batch sizes larger than 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94Xz9e-HWdIa",
        "outputId": "85a96baa-8eca-4340-b981-654d210a95ff"
      },
      "source": [
        "# Pull the total number of training images so we can calculate the maximum step number\n",
        "\n",
        "import csv\n",
        "\n",
        "training_subset_count = 0\n",
        "with open(subset_list_file) as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    for row in reader:\n",
        "      if \"training\" in row:\n",
        "        training_subset_count += 1\n",
        "print(training_subset_count)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q_jz-8wdJ-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89f8e160-1809-48fe-b540-7a1828df2a11"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "epoch_number = 50\n",
        "batch_size_number = 2\n",
        "step_number = int(training_subset_count/batch_size_number)\n",
        "print(str(step_number) + \" steps\" possible)\n",
        "\n",
        "# the following code gets passed to the terminal, but we've moved it into a\n",
        "# subprocess that pulls variables instead; use terminal code for troubleshooting\n",
        "# or for teaching when you want to see the training in action and use custom variables\n",
        "\n",
        "# (uncommented in for teaching purposes)\n",
        "! keras-retinanet/keras_retinanet/bin/train.py \\\n",
        "--weights data/resnet50_coco_best_v2.1.0.h5 \\\n",
        "--epochs 20 --steps 10 --batch-size 2 \\\n",
        "csv data/annotations_train.csv data/classes.csv \\\n",
        "--val-annotations data/annotations_valid.csv\n",
        "\n",
        "# this process takes a while to run, be warned! Consider running in terminal commands\n",
        "# (commented out above) if you want to see the live output as it's running\n",
        "\n",
        "# you can also monitor epoch outputs by output files in the \"output\" folder\n",
        "\n",
        "# (commented out for teaching purposes)\n",
        "model_run = subprocess.check_output(['keras-retinanet/keras_retinanet/bin/train.py',\n",
        "                 '--weights', 'data/resnet50_coco_best_v2.1.0.h5',\n",
        "                 '--epochs', str(epoch_number),  '--steps', str(step_number), '--batch-size',\n",
        "                 str(batch_size_number), 'csv', training_data_file, classes_file,\n",
        "                 '--val-annotations', validation_data_file]).decode(\"utf-8\")\n",
        "print(model_run)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "105 steps\n",
            "2021-07-02 21:36:55.207200: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Creating model, this may take a second...\n",
            "2021-07-02 21:36:56.492575: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2021-07-02 21:36:56.498487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-02 21:36:56.498938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-02 21:36:56.498972: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-07-02 21:36:56.500729: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2021-07-02 21:36:56.502340: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-02 21:36:56.502666: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-02 21:36:56.504580: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-02 21:36:56.505505: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-07-02 21:36:56.509607: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-07-02 21:36:56.509730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-02 21:36:56.510215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-02 21:36:56.510606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2021-07-02 21:36:56.510844: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-07-02 21:36:56.516231: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2000185000 Hz\n",
            "2021-07-02 21:36:56.516413: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556260c30bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-07-02 21:36:56.516440: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-07-02 21:36:56.602514: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-02 21:36:56.603160: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556260c30d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-07-02 21:36:56.603195: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2021-07-02 21:36:56.603376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-02 21:36:56.603826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-02 21:36:56.603870: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-07-02 21:36:56.603918: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2021-07-02 21:36:56.603941: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-02 21:36:56.603965: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-02 21:36:56.603985: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-02 21:36:56.604005: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-07-02 21:36:56.604024: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-07-02 21:36:56.604113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-02 21:36:56.604573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-02 21:36:56.604959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2021-07-02 21:36:56.605009: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-07-02 21:36:57.137315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-02 21:36:57.137375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2021-07-02 21:36:57.137388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2021-07-02 21:36:57.137593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-02 21:36:57.138132: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-02 21:36:57.138562: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-07-02 21:36:57.138602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9039 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:Skipping loading of weights for layer classification_submodel due to mismatch in shape ((3, 3, 256, 18) vs (3, 3, 256, 720)).\n",
            "WARNING:tensorflow:Skipping loading of weights for layer classification_submodel due to mismatch in shape ((18,) vs (720,)).\n",
            "Model: \"retinanet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, None, None, 6 9408        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, None, None, 6 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, None, None, 6 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, None, None, 6 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, None, None, 6 4096        pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, None, None, 6 256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a_relu (Activation (None, None, None, 6 0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding2a_branch2b (ZeroPadding (None, None, None, 6 0           res2a_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, None, None, 6 36864       padding2a_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, None, None, 6 256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b_relu (Activation (None, None, None, 6 0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, None, None, 2 16384       res2a_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, None, None, 2 16384       pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a (Add)                     (None, None, None, 2 0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_relu (Activation)         (None, None, None, 2 0           res2a[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, None, None, 6 16384       res2a_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, None, None, 6 256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a_relu (Activation (None, None, None, 6 0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding2b_branch2b (ZeroPadding (None, None, None, 6 0           res2b_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, None, None, 6 36864       padding2b_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, None, None, 6 256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b_relu (Activation (None, None, None, 6 0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, None, None, 2 16384       res2b_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2b (Add)                     (None, None, None, 2 0           bn2b_branch2c[0][0]              \n",
            "                                                                 res2a_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2b_relu (Activation)         (None, None, None, 2 0           res2b[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, None, None, 6 16384       res2b_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, None, None, 6 256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a_relu (Activation (None, None, None, 6 0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding2c_branch2b (ZeroPadding (None, None, None, 6 0           res2c_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, None, None, 6 36864       padding2c_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, None, None, 6 256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b_relu (Activation (None, None, None, 6 0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, None, None, 2 16384       res2c_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2c (Add)                     (None, None, None, 2 0           bn2c_branch2c[0][0]              \n",
            "                                                                 res2b_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2c_relu (Activation)         (None, None, None, 2 0           res2c[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, None, None, 1 32768       res2c_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, None, None, 1 512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a_relu (Activation (None, None, None, 1 0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding3a_branch2b (ZeroPadding (None, None, None, 1 0           res3a_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, None, None, 1 147456      padding3a_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, None, None, 1 512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b_relu (Activation (None, None, None, 1 0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, None, None, 5 65536       res3a_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, None, None, 5 131072      res2c_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a (Add)                     (None, None, None, 5 0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_relu (Activation)         (None, None, None, 5 0           res3a[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, None, None, 1 65536       res3a_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, None, None, 1 512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a_relu (Activation (None, None, None, 1 0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding3b_branch2b (ZeroPadding (None, None, None, 1 0           res3b_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, None, None, 1 147456      padding3b_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, None, None, 1 512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b_relu (Activation (None, None, None, 1 0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, None, None, 5 65536       res3b_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3b (Add)                     (None, None, None, 5 0           bn3b_branch2c[0][0]              \n",
            "                                                                 res3a_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res3b_relu (Activation)         (None, None, None, 5 0           res3b[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, None, None, 1 65536       res3b_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, None, None, 1 512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a_relu (Activation (None, None, None, 1 0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding3c_branch2b (ZeroPadding (None, None, None, 1 0           res3c_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, None, None, 1 147456      padding3c_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, None, None, 1 512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b_relu (Activation (None, None, None, 1 0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, None, None, 5 65536       res3c_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3c (Add)                     (None, None, None, 5 0           bn3c_branch2c[0][0]              \n",
            "                                                                 res3b_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res3c_relu (Activation)         (None, None, None, 5 0           res3c[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, None, None, 1 65536       res3c_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, None, None, 1 512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a_relu (Activation (None, None, None, 1 0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding3d_branch2b (ZeroPadding (None, None, None, 1 0           res3d_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, None, None, 1 147456      padding3d_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, None, None, 1 512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b_relu (Activation (None, None, None, 1 0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, None, None, 5 65536       res3d_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3d (Add)                     (None, None, None, 5 0           bn3d_branch2c[0][0]              \n",
            "                                                                 res3c_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res3d_relu (Activation)         (None, None, None, 5 0           res3d[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, None, None, 2 131072      res3d_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a_relu (Activation (None, None, None, 2 0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding4a_branch2b (ZeroPadding (None, None, None, 2 0           res4a_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, None, None, 2 589824      padding4a_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b_relu (Activation (None, None, None, 2 0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, None, None, 1 262144      res4a_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, None, None, 1 524288      res3d_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a (Add)                     (None, None, None, 1 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res4a_relu (Activation)         (None, None, None, 1 0           res4a[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, None, None, 2 262144      res4a_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a_relu (Activation (None, None, None, 2 0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding4b_branch2b (ZeroPadding (None, None, None, 2 0           res4b_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, None, None, 2 589824      padding4b_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b_relu (Activation (None, None, None, 2 0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, None, None, 1 262144      res4b_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4b (Add)                     (None, None, None, 1 0           bn4b_branch2c[0][0]              \n",
            "                                                                 res4a_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4b_relu (Activation)         (None, None, None, 1 0           res4b[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, None, None, 2 262144      res4b_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a_relu (Activation (None, None, None, 2 0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding4c_branch2b (ZeroPadding (None, None, None, 2 0           res4c_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, None, None, 2 589824      padding4c_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b_relu (Activation (None, None, None, 2 0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, None, None, 1 262144      res4c_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4c (Add)                     (None, None, None, 1 0           bn4c_branch2c[0][0]              \n",
            "                                                                 res4b_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4c_relu (Activation)         (None, None, None, 1 0           res4c[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, None, None, 2 262144      res4c_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a_relu (Activation (None, None, None, 2 0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding4d_branch2b (ZeroPadding (None, None, None, 2 0           res4d_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, None, None, 2 589824      padding4d_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b_relu (Activation (None, None, None, 2 0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, None, None, 1 262144      res4d_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4d (Add)                     (None, None, None, 1 0           bn4d_branch2c[0][0]              \n",
            "                                                                 res4c_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4d_relu (Activation)         (None, None, None, 1 0           res4d[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, None, None, 2 262144      res4d_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a_relu (Activation (None, None, None, 2 0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding4e_branch2b (ZeroPadding (None, None, None, 2 0           res4e_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, None, None, 2 589824      padding4e_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b_relu (Activation (None, None, None, 2 0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, None, None, 1 262144      res4e_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4e (Add)                     (None, None, None, 1 0           bn4e_branch2c[0][0]              \n",
            "                                                                 res4d_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4e_relu (Activation)         (None, None, None, 1 0           res4e[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, None, None, 2 262144      res4e_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a_relu (Activation (None, None, None, 2 0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding4f_branch2b (ZeroPadding (None, None, None, 2 0           res4f_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, None, None, 2 589824      padding4f_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b_relu (Activation (None, None, None, 2 0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, None, None, 1 262144      res4f_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4f (Add)                     (None, None, None, 1 0           bn4f_branch2c[0][0]              \n",
            "                                                                 res4e_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4f_relu (Activation)         (None, None, None, 1 0           res4f[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, None, None, 5 524288      res4f_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, None, None, 5 2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a_relu (Activation (None, None, None, 5 0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding5a_branch2b (ZeroPadding (None, None, None, 5 0           res5a_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, None, None, 5 2359296     padding5a_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, None, None, 5 2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b_relu (Activation (None, None, None, 5 0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, None, None, 2 1048576     res5a_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, None, None, 2 2097152     res4f_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, None, None, 2 8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, None, None, 2 8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a (Add)                     (None, None, None, 2 0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res5a_relu (Activation)         (None, None, None, 2 0           res5a[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, None, None, 5 1048576     res5a_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, None, None, 5 2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a_relu (Activation (None, None, None, 5 0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding5b_branch2b (ZeroPadding (None, None, None, 5 0           res5b_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, None, None, 5 2359296     padding5b_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, None, None, 5 2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b_relu (Activation (None, None, None, 5 0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, None, None, 2 1048576     res5b_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, None, None, 2 8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5b (Add)                     (None, None, None, 2 0           bn5b_branch2c[0][0]              \n",
            "                                                                 res5a_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res5b_relu (Activation)         (None, None, None, 2 0           res5b[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, None, None, 5 1048576     res5b_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, None, None, 5 2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a_relu (Activation (None, None, None, 5 0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding5c_branch2b (ZeroPadding (None, None, None, 5 0           res5c_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, None, None, 5 2359296     padding5c_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, None, None, 5 2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b_relu (Activation (None, None, None, 5 0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, None, None, 2 1048576     res5c_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, None, None, 2 8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5c (Add)                     (None, None, None, 2 0           bn5c_branch2c[0][0]              \n",
            "                                                                 res5b_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res5c_relu (Activation)         (None, None, None, 2 0           res5c[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "C5_reduced (Conv2D)             (None, None, None, 2 524544      res5c_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "P5_upsampled (UpsampleLike)     (None, None, None, 2 0           C5_reduced[0][0]                 \n",
            "                                                                 res4f_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "C4_reduced (Conv2D)             (None, None, None, 2 262400      res4f_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "P4_merged (Add)                 (None, None, None, 2 0           P5_upsampled[0][0]               \n",
            "                                                                 C4_reduced[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "P4_upsampled (UpsampleLike)     (None, None, None, 2 0           P4_merged[0][0]                  \n",
            "                                                                 res3d_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "C3_reduced (Conv2D)             (None, None, None, 2 131328      res3d_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "P6 (Conv2D)                     (None, None, None, 2 4718848     res5c_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "P3_merged (Add)                 (None, None, None, 2 0           P4_upsampled[0][0]               \n",
            "                                                                 C3_reduced[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "C6_relu (Activation)            (None, None, None, 2 0           P6[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "P3 (Conv2D)                     (None, None, None, 2 590080      P3_merged[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "P4 (Conv2D)                     (None, None, None, 2 590080      P4_merged[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "P5 (Conv2D)                     (None, None, None, 2 590080      C5_reduced[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "P7 (Conv2D)                     (None, None, None, 2 590080      C6_relu[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "regression_submodel (Functional (None, None, 4)      2443300     P3[0][0]                         \n",
            "                                                                 P4[0][0]                         \n",
            "                                                                 P5[0][0]                         \n",
            "                                                                 P6[0][0]                         \n",
            "                                                                 P7[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "classification_submodel (Functi (None, None, 2)      2401810     P3[0][0]                         \n",
            "                                                                 P4[0][0]                         \n",
            "                                                                 P5[0][0]                         \n",
            "                                                                 P6[0][0]                         \n",
            "                                                                 P7[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "regression (Concatenate)        (None, None, 4)      0           regression_submodel[0][0]        \n",
            "                                                                 regression_submodel[1][0]        \n",
            "                                                                 regression_submodel[2][0]        \n",
            "                                                                 regression_submodel[3][0]        \n",
            "                                                                 regression_submodel[4][0]        \n",
            "__________________________________________________________________________________________________\n",
            "classification (Concatenate)    (None, None, 2)      0           classification_submodel[0][0]    \n",
            "                                                                 classification_submodel[1][0]    \n",
            "                                                                 classification_submodel[2][0]    \n",
            "                                                                 classification_submodel[3][0]    \n",
            "                                                                 classification_submodel[4][0]    \n",
            "==================================================================================================\n",
            "Total params: 36,403,702\n",
            "Trainable params: 36,297,462\n",
            "Non-trainable params: 106,240\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From keras-retinanet/keras_retinanet/bin/train.py:604: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/20\n",
            "2021-07-02 21:37:07.642560: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-07-02 21:37:09.076651: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "Running network: 100% (10 of 10) |########| Elapsed Time: 0:00:04 Time:  0:00:04\n",
            "Parsing annotations: 100% (10 of 10) |####| Elapsed Time: 0:00:00 Time:  0:00:00\n",
            "13 instances of class Adult with average precision: 0.0000\n",
            "138 instances of class Pup with average precision: 0.0000\n",
            "mAP: 0.0000\n",
            "\n",
            "Epoch 00001: saving model to ./snapshots/resnet50_csv_01.h5\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.1133 - regression_loss: 1.2140 - classification_loss: 0.8993\n",
            "Epoch 2/20\n",
            "Running network: 100% (10 of 10) |########| Elapsed Time: 0:00:01 Time:  0:00:01\n",
            "Parsing annotations: 100% (10 of 10) |####| Elapsed Time: 0:00:00 Time:  0:00:00\n",
            "13 instances of class Adult with average precision: 0.0000\n",
            "138 instances of class Pup with average precision: 0.0000\n",
            "mAP: 0.0000\n",
            "\n",
            "Epoch 00002: saving model to ./snapshots/resnet50_csv_02.h5\n",
            "10/10 [==============================] - 8s 759ms/step - loss: 1.8805 - regression_loss: 1.0195 - classification_loss: 0.8609\n",
            "Epoch 3/20\n",
            "Running network: 100% (10 of 10) |########| Elapsed Time: 0:00:01 Time:  0:00:01\n",
            "Parsing annotations: 100% (10 of 10) |####| Elapsed Time: 0:00:00 Time:  0:00:00\n",
            "13 instances of class Adult with average precision: 0.0000\n",
            "138 instances of class Pup with average precision: 0.0000\n",
            "mAP: 0.0000\n",
            "\n",
            "Epoch 00003: saving model to ./snapshots/resnet50_csv_03.h5\n",
            "10/10 [==============================] - 7s 745ms/step - loss: 0.9347 - regression_loss: 0.3891 - classification_loss: 0.5456\n",
            "Epoch 4/20\n",
            "Running network: 100% (10 of 10) |########| Elapsed Time: 0:00:01 Time:  0:00:01\n",
            "Parsing annotations: 100% (10 of 10) |####| Elapsed Time: 0:00:00 Time:  0:00:00\n",
            "13 instances of class Adult with average precision: 0.0000\n",
            "138 instances of class Pup with average precision: 0.0000\n",
            "mAP: 0.0000\n",
            "\n",
            "Epoch 00004: saving model to ./snapshots/resnet50_csv_04.h5\n",
            "10/10 [==============================] - 10s 958ms/step - loss: 1.5415 - regression_loss: 0.8032 - classification_loss: 0.7383\n",
            "Epoch 5/20\n",
            "Running network: 100% (10 of 10) |########| Elapsed Time: 0:00:01 Time:  0:00:01\n",
            "Parsing annotations: 100% (10 of 10) |####| Elapsed Time: 0:00:00 Time:  0:00:00\n",
            "13 instances of class Adult with average precision: 0.0000\n",
            "138 instances of class Pup with average precision: 0.0000\n",
            "mAP: 0.0000\n",
            "\n",
            "Epoch 00005: saving model to ./snapshots/resnet50_csv_05.h5\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "10/10 [==============================] - 7s 744ms/step - loss: 1.9956 - regression_loss: 1.1213 - classification_loss: 0.8743\n",
            "Epoch 6/20\n",
            "Running network: 100% (10 of 10) |########| Elapsed Time: 0:00:01 Time:  0:00:01\n",
            "Parsing annotations: 100% (10 of 10) |####| Elapsed Time: 0:00:00 Time:  0:00:00\n",
            "13 instances of class Adult with average precision: 0.0000\n",
            "138 instances of class Pup with average precision: 0.0000\n",
            "mAP: 0.0000\n",
            "\n",
            "Epoch 00006: saving model to ./snapshots/resnet50_csv_06.h5\n",
            "10/10 [==============================] - 7s 737ms/step - loss: 2.2342 - regression_loss: 1.2949 - classification_loss: 0.9393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28P8eyNJ2BnO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95edf0ed-2117-4fe9-e87f-60316d98e161"
      },
      "source": [
        "list_of_files = glob.glob('snapshots/resnet*.h5')\n",
        "latest_file = max(list_of_files, key=os.path.getctime)\n",
        "epoch_final = latest_file[latest_file.index(\"_csv_\")+5:-3]\n",
        "best_model_training = latest_file.replace(\"/content/\", \"\")\n",
        "print(best_model_training)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "snapshots/resnet50_csv_06.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apHCQjSo8WC2"
      },
      "source": [
        "This next section converts the model from training mode to inference mode so it can be used to detect our target objects (seals). Until now we've been updating the model based on its performance; now we're fixing the model in a static \"snapshot\" so we can test it out. This conversion process take a little time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YyMralKEKuz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57fb7f6b-d1ed-4148-e062-dad4fe49b788"
      },
      "source": [
        "# note that we are naming our model \"best_model_inference\" and locating it in the \"snapshots\" directory. Customize if wanted\n",
        "model_name = \"best_model_inference\"\n",
        "#! keras-retinanet/keras_retinanet/bin/convert_model.py snapshots/resnet50_csv_10.h5 snapshots/best_model_inference.h5\n",
        "subprocess.run([\"keras-retinanet/keras_retinanet/bin/convert_model.py\", best_model_training, \"snapshots/{m}.h5\".format(m=model_name)])\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['keras-retinanet/keras_retinanet/bin/convert_model.py', 'snapshots/resnet50_csv_06.h5', 'snapshots/best_model_inference.h5'], returncode=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu3yk48fEKu2"
      },
      "source": [
        "### Run Detection in inference mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbTLLmbGEKu2"
      },
      "source": [
        "This section sets up the environment, importing modules for python tasks and specific to keras+retinanet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj-WmUXiEKu3"
      },
      "source": [
        "# show images inline\n",
        "%matplotlib inline\n",
        "\n",
        "# automatically reload modules when they have changed\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# import keras\n",
        "import keras\n",
        "\n",
        "# import keras_retinanet\n",
        "from keras_retinanet import models\n",
        "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
        "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
        "from keras_retinanet.utils.colors import label_color\n",
        "\n",
        "# import miscellaneous modules\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import json\n",
        "from random import shuffle\n",
        "\n",
        "# set tf backend to allow memory to grow, instead of claiming everything\n",
        "import tensorflow as tf\n",
        "\n",
        "def get_session():\n",
        "    config = tf.compat.v1.ConfigProto()    \n",
        "    config.gpu_options.allow_growth = True\n",
        "    return tf.compat.v1.Session(config=config)\n",
        "\n",
        "# use this environment flag to change which GPU to use\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "# set the modified tf session as backend in keras\n",
        "tf.compat.v1.keras.backend.set_session(get_session())"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w987GUwIEKu5"
      },
      "source": [
        "### Load RetinaNet model\n",
        "\n",
        "Now we will load the model that you just converted into inference mode: by default it is called `best_model_inference.h5`, but you might have renamed your model_name variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDo883mYEKu6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12bd9dca-6178-4636-b5ad-b5761d2c040a"
      },
      "source": [
        "model_path = 'snapshots/{m}.h5'.format(m=model_name)\n",
        "\n",
        "print(model_path)\n",
        "\n",
        "# load retinanet model\n",
        "model = models.load_model(model_path, backbone_name='resnet50')\n",
        "\n",
        "# you can check out a model summary by uncommenting this line\n",
        "#print(model.summary())\n",
        "\n",
        "# load label to names mapping for visualization purposes\n",
        "# pull labels from classes.csv\n",
        "import csv\n",
        "with open(classes_file, \"r\") as f:\n",
        "    reader = csv.reader(f, delimiter=\",\")\n",
        "    labels_to_names = {int(i[1]):i[0] for i in reader}"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "snapshots/best_model_inference.h5\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jfMnDLVEKu9"
      },
      "source": [
        "### Load test imagery\n",
        "\n",
        "Now we will load the \"testing\" subset of images that we downloaded into our data directory during setup (as listed in the subsets CSV file). Just to check, we'll print out the first five names of those images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QjtUN5wEKu9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82cf1cc2-885e-4e54-f403-97087ec3126b"
      },
      "source": [
        "# load imagery\n",
        "image_dir = \"data/\"\n",
        "\n",
        "# this code pulls only files from the test or validation subset\n",
        "# as specified in this variable, \"target_subset\" either \"test\" or \"validation\"\n",
        "target_subset = \"testing\"\n",
        "\n",
        "image_list = []\n",
        "with open(subset_list_file, \"r\") as f:\n",
        "    reader = csv.reader(f, delimiter=\",\")\n",
        "    for i in reader:\n",
        "      if i[1] == target_subset:\n",
        "        image_list.append(image_dir + i[0])\n",
        "print(image_list[:5])\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['data/2015_02_02_hay_island_flight03_s110rgb_jpeg_mosaic_group1---131.png', 'data/2015_02_02_hay_island_flight03_s110rgb_jpeg_mosaic_group1---124.png', 'data/2015_02_02_hay_island_flight03_s110rgb_jpeg_mosaic_group1---52.png', 'data/2015_02_02_hay_island_flight03_s110rgb_jpeg_mosaic_group1---111.png', 'data/2015_02_02_hay_island_flight03_s110rgb_jpeg_mosaic_group1---99.png']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "detiYRZWEKvA"
      },
      "source": [
        "### Test out detections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDezuFxm-xAf"
      },
      "source": [
        "Now we'll visualize some detections from our model to see how it performs. Each detection has a \"confidence score\" that describes the CNN's confidence that the detection is correct. Change the minimum confidence score (the first line of code) and re-run the code to check out how your \"confidence threshold\" affects the numbers of false positives and false negatives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I13IyhvEKvA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b03640e-1ec8-434d-9519-2c8ab35ecab3"
      },
      "source": [
        "min_score = 0.4 # this is the CNN's confidence that the detection is correct\n",
        "detection_iterations = 10 # max number of images to visualize\n",
        "\n",
        "visualize = True\n",
        "\n",
        "detections = {}\n",
        "\n",
        "total_time = 0\n",
        "\n",
        "count = 0\n",
        "shuffle(image_list)\n",
        "\n",
        "for image_path in image_list:\n",
        "    if count > detection_iterations:\n",
        "        break\n",
        "    else:\n",
        "        count +=1\n",
        "        \n",
        "    image = read_image_bgr(image_path)\n",
        "\n",
        "    if visualize:\n",
        "        # copy to draw on\n",
        "        draw = image.copy()\n",
        "        draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # preprocess image for network\n",
        "    image = preprocess_image(image)\n",
        "    image, scale = resize_image(image)\n",
        "\n",
        "    # process image\n",
        "    start = time.time()\n",
        "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
        "    total_time += time.time() - start\n",
        "\n",
        "    # correct for image scale\n",
        "    boxes /= scale\n",
        "    if any(score >= min_score for score in scores[0]):\n",
        "        detections[image_path] = []\n",
        "\n",
        "    # visualize detections\n",
        "    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
        "        # scores are sorted so we can break\n",
        "        if score < min_score:\n",
        "            break\n",
        "\n",
        "        #print(score)\n",
        "        #print(box)\n",
        "\n",
        "        # TODO this does create a slight error in the boxes, might be worth doing something like\n",
        "        # list(map(str, box) but then would need to cast on the other end back to float\n",
        "        b = box.astype(int)\n",
        "        detections[image_path].append({\"box\" : b, \"label\" : label, \"score\" : score})\n",
        "\n",
        "        if visualize:\n",
        "            color = label_color(label)\n",
        "\n",
        "            # b = box.astype(int)\n",
        "            draw_box(draw, b, color=color)\n",
        "\n",
        "            caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
        "            draw_caption(draw, b, caption)\n",
        "\n",
        "    if any(score >= min_score for score in scores[0]):\n",
        "        if visualize:\n",
        "            plt.figure(figsize=(10, 10))\n",
        "            plt.axis('off')\n",
        "            plt.imshow(draw)\n",
        "            plt.show()\n",
        "    \n",
        "print(\"Finished, time per image:\", total_time/len(image_list))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished, time per image: 0.29682718714078266\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_Khk5BWEKvD"
      },
      "source": [
        "### Run Detections on all tiles\n",
        "This section repeats the process we just tested for all tiles that make up our orthomosaic. If you want to experiment, you can vary the confidence threshold and the amount of time the model trains, then look at how it affects the resulting detections.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Tvuim_vEKvE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9817ad25-b848-44c7-f52a-dc0a38a020cc"
      },
      "source": [
        "visualize = False\n",
        "min_score = min_score # this is the CNN's confidence that the detection is correct\n",
        "\n",
        "detections = {}\n",
        "\n",
        "total_time = 0\n",
        "\n",
        "for image_path in image_list:\n",
        "       \n",
        "    image = read_image_bgr(image_path)\n",
        "\n",
        "    if visualize:\n",
        "        # copy to draw on\n",
        "        draw = image.copy()\n",
        "        draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # preprocess image for network\n",
        "    image = preprocess_image(image)\n",
        "    image, scale = resize_image(image)\n",
        "\n",
        "    # process image\n",
        "    start = time.time()\n",
        "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
        "    total_time += time.time() - start\n",
        "\n",
        "    # correct for image scale\n",
        "    boxes /= scale\n",
        "    if any(score >= min_score for score in scores[0]):\n",
        "        detections[image_path] = []\n",
        "\n",
        "    # visualize detections\n",
        "    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
        "        # scores are sorted so we can break\n",
        "        if score < min_score:\n",
        "            break\n",
        "\n",
        "        #print(score)\n",
        "        #print(box)\n",
        "\n",
        "        # TODO this does create a slight error in the boxes, might be worth doing something like\n",
        "        # list(map(str, box) but then would need to cast on the other end back to float\n",
        "        b = box.astype(int)\n",
        "        detections[image_path].append({\"box\" : b, \"label\" : label, \"score\" : score})\n",
        "\n",
        "        if visualize:\n",
        "            color = label_color(label)\n",
        "\n",
        "            # b = box.astype(int)\n",
        "            draw_box(draw, b, color=color)\n",
        "\n",
        "            caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
        "            draw_caption(draw, b, caption)\n",
        "\n",
        "    if any(score >= min_score for score in scores[0]):\n",
        "        if visualize:\n",
        "            plt.figure(figsize=(10, 10))\n",
        "            plt.axis('off')\n",
        "            plt.imshow(draw)\n",
        "            plt.show()\n",
        "    \n",
        "print(\"Finished, time per image:\", total_time/len(image_list))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished, time per image: 0.07058683037757874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P3nBtjv81_J"
      },
      "source": [
        "Run an evaluation script to get the mean average precision (mAP) of the CNN. \n",
        "\n",
        "mAP is a model evaluation metric that is relative (aka it can be challenging to compare mAP values across datasets), but a great general metric for different models and approaches to detection objects on the same dataset. \n",
        "\n",
        "Read more about mAP here: https://tarangshah.com/blog/2018-01-27/what-is-map-understanding-the-statistic-of-choice-for-comparing-object-detection-models/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CKEvUTb1JC0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96c52cf9-d16e-4b26-f466-ee5b7dba3022"
      },
      "source": [
        "#! keras-retinanet/keras_retinanet/bin/evaluate.py csv data/annotations_test.csv data/classes.csv snapshots/test_model.h5\n",
        "\n",
        "precision_metrics = subprocess.check_output(['keras-retinanet/keras_retinanet/bin/evaluate.py', 'csv', testing_data_file, classes_file, model_path]).decode(\"utf-8\")\n",
        "model_summary = str('Model {m} was generated using {e} epochs, {s} steps and {b} batches'.format(m=model_name, e=epoch_final, s=step_number, b=batch_size_number))\n",
        "print(model_summary)\n",
        "print(precision_metrics)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model best_model_inference was generated using 06 epochs, 10 steps and 2 batches\n",
            "Loading model, this may take a second...\n",
            "81 instances of class Adult with average precision: 0.0000\n",
            "307 instances of class Pup with average precision: 0.0000\n",
            "Inference time for 24 images: 0.3287\n",
            "mAP using the weighted average of precisions among classes: 0.0000\n",
            "mAP: 0.0000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SyoUJ6REKvJ"
      },
      "source": [
        "### Export detections##\n",
        "Write out the detections to a json file that can be used in a GIS for  spatial databases and/or visualizations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-zIVPAVEKvH"
      },
      "source": [
        "class MyEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.integer):\n",
        "            return int(obj)\n",
        "        elif isinstance(obj, np.floating):\n",
        "            return float(obj)\n",
        "        elif isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        else:\n",
        "            return super(MyEncoder, self).default(obj)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd3NXa3wEKvK"
      },
      "source": [
        "output_file_name = 'data/new_detections.json'\n",
        "with open(output_file_name, 'w') as fp:\n",
        "    json.dump(detections, fp, cls=MyEncoder)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-6WjaR1EKvM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f19d8460-74d6-4391-90bd-32b66fb4abab"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/\" + output_file_name)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7a63565d-2ac3-46ea-8b1d-250b79711bab\", \"new_detections.json\", 2)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgDzXkfvcOhk"
      },
      "source": [
        "### Export model and metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8ndsVTJcOhl"
      },
      "source": [
        "# export metrics (fast)\n",
        "files.download(\"/content/output/Epoch-{n}.png\".format(n=epoch_final))\n",
        "files.download(\"/content/output/Epoch-{n}.csv\".format(n=epoch_final))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1lQjgH6Sy5z"
      },
      "source": [
        "#export inference model (slow)\n",
        "files.download(\"/content/{m}\".format(m=model_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8Nz2tu_xDqg"
      },
      "source": [
        "#export training model (even slower)\n",
        "files.download(\"/content/{m}\".format(m=best_model_training))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ24IwaycOhl"
      },
      "source": [
        "#### At the end of this script you should have a single `json` file downloaded (in addition model training metrics in `png` and `csv` format), and two versions of the final model: an inferential version for deployment and a training version for additional training applications. Drop the `json` in the Google Drive folder so it can be imported in the next step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ3OzkdicOhm"
      },
      "source": [
        "Next steps:\n",
        "\n",
        "5) export CNN outputs"
      ]
    }
  ]
}