{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert VIA annotations export .csv file to RetinaNet .csv format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Greg has adapted this from the script Patrick and Maddie used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "\n",
    "# set pseudo-random values for replicability\n",
    "random.seed(1)\n",
    "\n",
    "# set directory to root where files live\n",
    "os.chdir('C:/Users/Greg/Documents/GitHub/GreySealCNN')\n",
    "\n",
    "# set path to VIA exported CSCV file\n",
    "via_path = 'data/via_SealCNN_TrainingData.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull names of data files, shuffle, and split into 3 datasets: training, testing, validation\n",
    "###### Script adapted from Maddie's version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 9 192\n"
     ]
    }
   ],
   "source": [
    "# pull images from directory where they live into a list\n",
    "path_images = 'data/Hay Island tiles'\n",
    "image_list = [f for f in os.listdir(path_images) if f.endswith('.png')]\n",
    "#print(image_list[:5])\n",
    "\n",
    "# shuffle the list randomly and get total count\n",
    "random.shuffle(image_list)\n",
    "total_count = len(image_list)\n",
    "\n",
    "# set indices for breaking up the total dataset into TTV parts\n",
    "test_fraction = 0.1\n",
    "valid_fraction = 0.04\n",
    "train_fraction = 0.86\n",
    "if (sum([test_fraction, valid_fraction, train_fraction]) != 1.0):\n",
    "   raise NameError(\"fractions should add up to 1\")\n",
    "\n",
    "test_index = int(total_count * test_fraction)\n",
    "valid_index = int(total_count * (test_fraction + valid_fraction))\n",
    "\n",
    "# use indices to break up dataset into TTV parts\n",
    "test_dataset = image_list[:test_index]\n",
    "valid_dataset = image_list[test_index:valid_index]\n",
    "train_dataset = image_list[valid_index:]\n",
    "print(len(test_dataset), len(valid_dataset), len(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following loop pulls each annotation, line-by-line, from the VIA exported CSV, extracts the necessary information, reformats it into the format that RetinaNet requires (https://github.com/fizyr/keras-retinanet#annotations-format), end then reassembles a new CSV line-by-line that RetinaNet can receive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#GDL has overhauled this code to ingest annotations exported as CSV from VIA 2.0.10\n",
    "\n",
    "# Create blank variable for each annotations list as we build it\n",
    "image_annotations_train = []\n",
    "image_annotations_test = []\n",
    "image_annotations_valid = []\n",
    "\n",
    "with open(via_path, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=\",\")\n",
    "    for line in reader: \n",
    "        # output we want\n",
    "        # path/to/image.jpg,x1,y1,x2,y2,class_name\n",
    "        # /data/imgs/img_001.jpg,837,346,981,456,cow\n",
    "        if 'filename' in line[0]:\n",
    "            # bypassing comments in csv\n",
    "            continue\n",
    "        if '{}' in line[5]:\n",
    "            #bypassing empty images\n",
    "            continue\n",
    "        filename = line[0]\n",
    "        \n",
    "        # pulling from column named \"region_shape_attributes\"\n",
    "        box_entry = list(str(line[5]).strip('}{').split(','))\n",
    "        box_entry = [i.split(':')[1] for i in box_entry]\n",
    "        # strip brackets, split and get only the values we care about, then convert all the string to int \n",
    "        top_left_x, top_left_y, width, height = list(map(int,list(map(float, box_entry[1:5]))))\n",
    "        if width == 0 or height == 0:\n",
    "            continue\n",
    "            # skip tiny/empty boxes\n",
    "        \n",
    "        # convert from \"top left and width/height\" to \"x and y values at each corner of the box\"\n",
    "        if top_left_x < 0:\n",
    "            top_left_x = 1\n",
    "        if top_left_y < 0:\n",
    "            top_left_y = 1\n",
    "        x1 = top_left_x\n",
    "        x2 = top_left_x + width\n",
    "        y1 = top_left_y\n",
    "        y2 = top_left_y + height \n",
    "        \n",
    "        # pulling from column named \"region_attributes\" to get class names\n",
    "        name = list(str(line[6]).strip('}{').split(':'))[1].strip('\"')\n",
    "\n",
    "        # skip unknown class, in this case. Might be useful in other applications though, e.g. total count\n",
    "        if name == \"Unknown\":\n",
    "            continue\n",
    "            \n",
    "\n",
    "        # create the csv row\n",
    "        new_row = []\n",
    "        new_row.append(filename)\n",
    "        new_row.append(x1)\n",
    "        new_row.append(y1)\n",
    "        new_row.append(x2)\n",
    "        new_row.append(y2)\n",
    "        new_row.append(name)\n",
    "        \n",
    "        # append the row to the correct CSV, depending on which part it belongs to\n",
    "        if filename in train_dataset:\n",
    "            image_annotations_train.append(new_row)\n",
    "        elif filename in test_dataset:\n",
    "            image_annotations_test.append(new_row)\n",
    "        else:\n",
    "            image_annotations_valid.append(new_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output annotations.csv and classes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/annotations_train.csv', 'w', newline='') as fp:\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerows(image_annotations_train)\n",
    "\n",
    "with open('data/annotations_test.csv', 'w', newline='') as fp:\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerows(image_annotations_test)\n",
    "\n",
    "with open('data/annotations_valid.csv', 'w', newline='') as fp:\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerows(image_annotations_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we were trying to generalize this, we'd be tracking new class names as they show up,\n",
    "# assigning values and automating construction of our list of classes...\n",
    "# but with only three classes, screw it, we'll just write them manually\n",
    "\n",
    "# also, note that \"unknown\" ambiguous cases have been excluded\n",
    "detection_classes = [[\"Adult\", 0], [\"Pup\", 1]]\n",
    "with open('data/classes.csv', 'w', newline='') as fp:\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerows(detection_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not a code issue, but I recommend manually checking each annotations document to make sure that there are a reasonable number of annotations in each dataset; it is possible that the random breakdown could pick a cluster of \"empty\" images for validation or training. Should not be an issue in this specific case because I've checked it for our random seed, but in future applications this is a good idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
