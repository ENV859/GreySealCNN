{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset and convert VIA annotations CSV file to RetinaNet CSV format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before running this script, make sure that your Google Drive folder contains the tiles you created (step 1) and the annotations CSV that you exported from VIA (step 2) and no other CSV or PNG files (if multiple CSV files are present, you will need to modify code to point to the exact file). It's fine if the orthomosaic and JSON files are in there (they will be ignored)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/gl7176/GreySealCNN/blob/master/3_VIA_to_RetinaNet_subsetted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "#####  <center> Be sure to update this hyperlink above if you clone and want to point to a different GitHub </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to our Google Drive folder and pull annotation CSV\n",
    "Note: when you run this it will give you a link that you must click. You must give Google some permissions, then copy a code into a box that comes up in the output section of this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive\n",
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# 1. Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# choose a local (colab) directory to store the data.\n",
    "local_download_path = os.path.expanduser('VIA_annotations')\n",
    "try:\n",
    "  os.makedirs(local_download_path)\n",
    "except: pass\n",
    "\n",
    "# 2. Auto-iterate using the query syntax\n",
    "#    https://developers.google.com/drive/v2/web/search-parameters\n",
    "\n",
    "# set variable to the destination google drive folder you want to pull from\n",
    "drive_folder = 'https://drive.google.com/drive/folders/1INuRNVKvKMy8L_Nb6lmoVbyvScWK0-0D'\n",
    "\n",
    "# this bit points the code to that google drive folder\n",
    "pointer = str(\"'\" + drive_folder.split(\"/\")[-1] + \"'\" + \" in parents\")\n",
    "\n",
    "file_list = drive.ListFile(\n",
    "    {'q': pointer}).GetList()\n",
    "\n",
    "# this bit examines every file in the directory specified above and pulls the first CSV file it finds\n",
    "# it also compiles the list of all images\n",
    "\n",
    "# if there are multiple CSV files present it will spit an error and you should modify the code\n",
    "# to point to the intended CSV file and re-run it\n",
    "\n",
    "annotations_file = {}\n",
    "image_list = []\n",
    "\n",
    "count = 0\n",
    "for f in file_list:\n",
    "  count += 1\n",
    "  if count % 10 == 0:\n",
    "    print(count)\n",
    "  # 3. Create & download CSV annotations file\n",
    "  fname = os.path.join(local_download_path, f['title'])\n",
    "  if fname.endswith(\".png\"):\n",
    "    image_list.append(fname.split(\"/\")[1])\n",
    "  if fname.endswith(\".csv\"): \n",
    "      if len(annotations_file) != 0:\n",
    "            if fname.endswith(\"classes.csv\") or fname.endswith(\"subset_list.csv\"):\n",
    "              pass\n",
    "            else:\n",
    "              raise Exception(\"more than one annotations file identified (\" + fname + \" was unexpected)\")\n",
    "      annotations_file = fname\n",
    "      f_ = drive.CreateFile({'id': f['id']})\n",
    "f_.GetContentFile(annotations_file)\n",
    "print(\"annotations file identified as \" + annotations_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the python environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "\n",
    "# if running code on a local machine, manually point to the annotations_file\n",
    "annotations_file = annotations_file\n",
    "\n",
    "# set pseudo-random values for replicability\n",
    "random.seed(1)\n",
    "\n",
    "# use this variable to set output directory\n",
    "output_dir = 'RetinaNet_annotations'\n",
    "\n",
    "# create the dir if it doesn't already exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle and split images into 3 datasets: Training, Testing, Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the image list randomly and get total count\n",
    "random.shuffle(image_list)\n",
    "total_count = len(image_list)\n",
    "\n",
    "# set indices for breaking up the total dataset into TTV parts\n",
    "test_fraction = 0.1\n",
    "valid_fraction = 0.04\n",
    "train_fraction = 0.86\n",
    "\n",
    "# spit error if the math don't add up\n",
    "if (sum([test_fraction, valid_fraction, train_fraction]) != 1.0):\n",
    "   raise Exception(\"fractions should add up to 1\")\n",
    "\n",
    "test_index = int(total_count * test_fraction)\n",
    "valid_index = int(total_count * (test_fraction + valid_fraction))\n",
    "\n",
    "# use indices to break up dataset into TTV parts\n",
    "test_dataset = image_list[:test_index]\n",
    "valid_dataset = image_list[test_index:valid_index]\n",
    "train_dataset = image_list[valid_index:]\n",
    "print(len(test_dataset), len(valid_dataset), len(train_dataset))\n",
    "\n",
    "# spit out CSV listing the image subsets\n",
    "subset_list = []\n",
    "for row in test_dataset:\n",
    "        new_row = []\n",
    "        new_row.append(row)\n",
    "        new_row.append(\"test\")\n",
    "        subset_list.append(new_row)\n",
    "for row in valid_dataset:\n",
    "        new_row = []\n",
    "        new_row.append(row)\n",
    "        new_row.append(\"validation\")\n",
    "        subset_list.append(new_row)\n",
    "for row in train_dataset:\n",
    "        new_row = []\n",
    "        new_row.append(row)\n",
    "        new_row.append(\"training\")\n",
    "        subset_list.append(new_row)\n",
    "with open(output_dir + '/subset_list.csv', 'w', newline='') as fp:\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerows(subset_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat annotations from VIA to RetinaNet format\n",
    "The following loop pulls each annotation, line-by-line, from the VIA exported CSV, extracts the necessary information, reformats it into the format that RetinaNet requires (https://github.com/fizyr/keras-retinanet#annotations-format), then reassembles a new CSV line-by-line that RetinaNet can receive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'annotations_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e1194964ca45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# read each line, parse it, convert it, put it all back together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# then drop it in the appropriate subset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotations_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'annotations_file' is not defined"
     ]
    }
   ],
   "source": [
    "# Create blank variable for each annotations list as we build it\n",
    "image_annotations_train = []\n",
    "image_annotations_test = []\n",
    "image_annotations_valid = []\n",
    "\n",
    "# Create blank list for class names\n",
    "class_list = []\n",
    "\n",
    "# read each line, parse it, convert it, put it all back together\n",
    "# then drop it in the appropriate subset\n",
    "with open(annotations_file, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=\",\")\n",
    "    for line in reader: \n",
    "        # output we want:\n",
    "        # format: path/to/image.jpg,x1,y1,x2,y2,class_name\n",
    "        # example: /data/imgs/img_001.jpg,837,346,981,456,cow\n",
    "        if 'filename' in line[0]:\n",
    "            # bypassing comments in csv\n",
    "            continue\n",
    "        if '{}' in line[5]:\n",
    "            #bypassing empty images\n",
    "            continue\n",
    "            \n",
    "        filename = line[0]\n",
    "        \n",
    "        # pulling from column named \"region_shape_attributes\"\n",
    "        box_entry = list(str(line[5]).strip('}{').split(','))\n",
    "        box_entry = [i.split(':')[1] for i in box_entry]\n",
    " \n",
    "        # strip brackets, split and get only the values we care about, then convert all the string to int \n",
    "        top_left_x, top_left_y, width, height = list(map(int,list(map(float, box_entry[1:5]))))\n",
    "        if width == 0 or height == 0:\n",
    "            continue\n",
    "            # skip tiny/empty boxes\n",
    "        \n",
    "        # convert from \"top left and width/height\" to \"x and y values at each corner of the box\"\n",
    "        if top_left_x < 0:\n",
    "            top_left_x = 1\n",
    "        if top_left_y < 0:\n",
    "            top_left_y = 1\n",
    "        x1 = top_left_x\n",
    "        x2 = top_left_x + width\n",
    "        y1 = top_left_y\n",
    "        y2 = top_left_y + height \n",
    "        \n",
    "        # pulling from column named \"region_attributes\" to get class names\n",
    "        name = list(str(line[6]).strip('}{').split(':'))[1].strip('\"')\n",
    "\n",
    "        # skip unknown class, in this case. Might be useful in other applications though, e.g. total count\n",
    "        if name == \"Unknown\":\n",
    "            continue\n",
    "\n",
    "        # build list of classes as we encounter new names\n",
    "        if name not in class_list:\n",
    "            class_list.append(name)\n",
    "\n",
    "          # create the annotation row\n",
    "        new_row = []\n",
    "        new_row.append(filename)\n",
    "        new_row.append(x1)\n",
    "        new_row.append(y1)\n",
    "        new_row.append(x2)\n",
    "        new_row.append(y2)\n",
    "        new_row.append(name)\n",
    "        \n",
    "        # append the row to the correct subset (training, testing, or validation)\n",
    "        if filename in train_dataset:\n",
    "            image_annotations_train.append(new_row)\n",
    "        elif filename in test_dataset:\n",
    "            image_annotations_test.append(new_row)\n",
    "        else:\n",
    "            image_annotations_valid.append(new_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output annotations.csv and classes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_dir + '/annotations_train.csv', 'w', newline='') as fp:\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerows(image_annotations_train)\n",
    "\n",
    "with open(output_dir + '/annotations_test.csv', 'w', newline='') as fp:\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerows(image_annotations_test)\n",
    "\n",
    "with open(output_dir + '/annotations_valid.csv', 'w', newline='') as fp:\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerows(image_annotations_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this bit uses our class_list (built during annotations processing) to create our classes file\n",
    "# note again that \"unknown\" ambiguous cases have been excluded in this case\n",
    "\n",
    "detection_classes = []\n",
    "\n",
    "for i in range(0, len(class_list)):\n",
    "    detection_classes.append([class_list[i], i])\n",
    "\n",
    "with open(output_dir + '/classes.csv', 'w', newline='') as fp:\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerows(detection_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zip data folder for download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip up the output directory into an archive for download\n",
    "import subprocess\n",
    "subprocess.call(['zip', '-r', '/content/' + output_dir + '.zip', '/content/' + output_dir])\n",
    "\n",
    "from google.colab import files\n",
    "files.download(\"/content/\" + output_dir + \".zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### At the end of this script you should have downloaded 3 TXT files (T/T/V) and 4 CSV files (T/T/V + classes). Drop these all in the google directory so they can be ingested by our CNN code in the next step.\n",
    "\n",
    "Next steps:\n",
    "\n",
    "4) train, refine, and test CNN using VIA annotations and the tiles generated here\n",
    "\n",
    "5) export CNN outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Not a code issue, but I recommend manually checking each annotations document to make sure that there are a reasonable number of annotations in each dataset; it is possible that the random breakdown could pick a cluster of \"empty\" images for validation or training. Should not be an issue in this specific case because I've checked it for our random seed, but in future applications this is a good idea."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
